{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43244,"status":"ok","timestamp":1661165641041,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"YS1uxj-59UmA","outputId":"68807f91-be09-4788-bb77-99580b9fbb8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 397 kB 11.1 MB/s \n","\u001b[K     |████████████████████████████████| 211 kB 60.3 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 6.2 MB 28.4 MB/s \n","\u001b[K     |████████████████████████████████| 4.7 MB 75.4 MB/s \n","\u001b[K     |████████████████████████████████| 281 kB 95.9 MB/s \n","\u001b[K     |████████████████████████████████| 7.4 MB 50.9 MB/s \n","\u001b[K     |████████████████████████████████| 81 kB 3.2 MB/s \n","\u001b[K     |████████████████████████████████| 93 kB 2.5 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 53.9 MB/s \n","\u001b[K     |████████████████████████████████| 101 kB 9.5 MB/s \n","\u001b[?25h  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 165.0 MB 35 kB/s \n","\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pickle5\n","  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n","\u001b[K     |████████████████████████████████| 256 kB 7.3 MB/s \n","\u001b[?25hInstalling collected packages: pickle5\n","Successfully installed pickle5-0.0.12\n"]}],"source":["!pip install mumin[all]==1.6.2 torchmetrics==0.7.2 --quiet\n","!pip install dgl-cu111==0.7.2 -f https://data.dgl.ai/wheels/repo.html --quiet\n","!pip install pickle5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtJqEQ-bsX3h"},"outputs":[],"source":["from mumin import MuminDataset\n","from google.colab import drive\n","from pathlib import Path\n","import shutil\n","import re\n","import pickle5 as pickle\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":46500,"status":"ok","timestamp":1661165687953,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"co2X-FT-C_Ag","outputId":"74b079f1-f866-421b-f6b4-2ea3508a3ad8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'mumin-small.zip'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["drive_dir = Path('drive')\n","drive.mount(str(drive_dir.resolve()), force_remount=True)\n","drive_content_dir = [child for child in drive_dir.iterdir() \n","                     if re.search(r'My ?Drive', str(child.stem)) is not None][0]\n","shutil.copy(drive_content_dir / 'mumin-small.zip', 'mumin-small.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKzCFln92Pmd"},"outputs":[],"source":["with open ('/content/drive/MyDrive/mumin-small/emb/multilingual_emb_sml_tweet.pkl', 'rb') as f:\n","    file1 = pd.DataFrame(pickle.load(f))\n","with open ('/content/drive/MyDrive/mumin-small/emb/text_emb_sml_reply.pkl', 'rb') as f:\n","    file2 = pd.DataFrame(pickle.load(f))\n","with open ('/content/drive/MyDrive/mumin-small/emb/multilingual_emb_sml_reply.pkl', 'rb') as f:\n","    file3 = pd.DataFrame(pickle.load(f))\n","with open ('/content/drive/MyDrive/mumin-small/emb/text_emb_sml_tweet.pkl', 'rb') as f:\n","    file4 = pd.DataFrame(pickle.load(f))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":16460,"status":"ok","timestamp":1661165714768,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"eeZYAbZLu_mM","outputId":"efe1e55d-ef95-45cc-bd32-d2297e2ec0aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'mumin-small.zip'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["drive_dir = Path('drive')\n","drive.mount(str(drive_dir.resolve()), force_remount=True)\n","drive_content_dir = [child for child in drive_dir.iterdir() \n","                     if re.search(r'My ?Drive', str(child.stem)) is not None][0]\n","shutil.copy(drive_content_dir / 'mumin-small.zip', 'mumin-small.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1661168272425,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"ekKc__BBRPuu","outputId":"256393de-f4c5-42b5-9876-cd6b00386092"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MuminDataset(size=small, compiled=False)"]},"metadata":{},"execution_count":43}],"source":["dataset = MuminDataset('mumin-small.zip')\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10813,"status":"ok","timestamp":1661168284974,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"_Ow0vBqMRj5U","outputId":"7c1d79de-a2d6-44db-cefe-1efb9bfa132c"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:mumin.dataset:Loading dataset\n"]},{"output_type":"execute_result","data":{"text/plain":["MuminDataset(num_nodes=392,419, num_relations=483,029, size='small', compiled=True)"]},"metadata":{},"execution_count":44}],"source":["dataset.compile()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mh98vmVCRabW"},"outputs":[],"source":["dataset.nodes['tweet']['mbert_emb'] = file1['mbert_mbert_auto_4']\n","dataset.nodes['tweet']['text_emb'] = file4['tweet_text_auto_64']\n","\n","dataset.nodes['reply']['mbert_emb'] = file3['mbert_auto_16']\n","dataset.nodes['reply']['text_emb'] = file2['auto_32']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Vhd7b0gTmZM"},"outputs":[],"source":["with open(\"/content/drive/MyDrive/mumin-small/emb/tweet_emb.pickle\", \"wb\") as fp:   #Pickling\n","    pickle.dump(dataset.nodes['tweet'], fp)  \n","with open(\"/content/drive/MyDrive/mumin-small/emb/reply_emb.pickle\", \"wb\") as fp:   #Pickling\n","    pickle.dump(dataset.nodes['reply'], fp)  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3976,"status":"ok","timestamp":1661117498223,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"lJBMGAOQxMxh","outputId":"bee45499-fb9f-49b1-9a14-5a22c06a1f9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["drive_dir = Path('drive')\n","drive.mount(str(drive_dir.resolve()), force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12707,"status":"ok","timestamp":1661116887120,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"3vRRKnKjxMxh","outputId":"643a8f02-dfc2-4462-a41b-ecb135dc70a6"},"outputs":[{"data":{"text/plain":["PosixPath('drive/MyDrive/mumin-small_reduced.zip')"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["drive_content_dir = [child for child in drive_dir.iterdir() \n","                     if re.search(r'My ?Drive', str(child.stem)) is not None][0]\n","shutil.copy('mumin-small.zip', drive_content_dir / 'mumin-small_reduced.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16692,"status":"ok","timestamp":1661116982111,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"QUHvRzj5oS7r","outputId":"110b9c91-5bbc-4da3-9ec9-203d12d36677"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]},{"data":{"text/plain":["PosixPath('drive/MyDrive/mumin-small_reduced.zip')"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["drive_dir = Path('drive')\n","drive_content_dir = [child for child in drive_dir.iterdir() \n","                     if re.search(r'My ?Drive', str(child.stem)) is not None][0]\n","drive.mount(str(drive_dir.resolve()), force_remount=True)\n","shutil.copy('mumin-small.zip', drive_content_dir / 'mumin-small_reduced.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLffgtxfk9VQ"},"outputs":[],"source":["from PIL import Image\n","import itertools as it"]},{"cell_type":"markdown","metadata":{"id":"Vs-T5oRsPfyT"},"source":["<center><img src=\"https://filedn.com/lRBwPhPxgV74tO0rDoe8SpH/metagraph.png\" alt=\"meta graph of the MuMiN dataset\" width=\"60%\"/></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1661107223351,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"nj-kY2uuHtuv","outputId":"1b52996c-3cf4-4dc9-9674-025ca2d9d438"},"outputs":[{"data":{"text/plain":["['claim', 'tweet', 'user', 'image', 'article', 'hashtag', 'reply']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["list(dataset.nodes.keys())"]},{"cell_type":"markdown","metadata":{"id":"dIkW-8ZjUFPO"},"source":["## 5. Building a graph misinformation classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDsnBoO40byY"},"outputs":[],"source":["from mumin import save_dgl_graph, load_dgl_graph\n","import dgl\n","import dgl.nn.pytorch as dglnn\n","import dgl.dataloading as D\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch\n","import torchmetrics as tm\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from collections import defaultdict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1661168295960,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"6TFxRMIwUIck","outputId":"28c9158d-3428-4fe6-eebc-cd0f2f890a9f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Graph(num_nodes={'article': 1497, 'claim': 2127, 'hashtag': 28820, 'image': 1036, 'reply': 186602, 'tweet': 4178, 'user': 158995},\n","      num_edges={('article', 'has_article_inv', 'tweet'): 1969, ('claim', 'discusses_inv', 'tweet'): 4890, ('hashtag', 'has_hashtag_inv', 'tweet'): 2343, ('hashtag', 'has_hashtag_inv', 'user'): 52420, ('image', 'has_image_inv', 'tweet'): 1045, ('reply', 'posted_inv', 'user'): 186602, ('reply', 'quote_of', 'tweet'): 93926, ('reply', 'reply_to', 'tweet'): 84271, ('tweet', 'discusses', 'claim'): 4890, ('tweet', 'has_article', 'article'): 1969, ('tweet', 'has_hashtag', 'hashtag'): 2343, ('tweet', 'has_image', 'image'): 1045, ('tweet', 'mentions', 'user'): 1134, ('tweet', 'posted_inv', 'user'): 4178, ('tweet', 'quote_of_inv', 'reply'): 93926, ('tweet', 'reply_to_inv', 'reply'): 84271, ('tweet', 'retweeted_inv', 'user'): 13710, ('user', 'follows', 'user'): 19886, ('user', 'follows_inv', 'user'): 19886, ('user', 'has_hashtag', 'hashtag'): 52420, ('user', 'mentions', 'user'): 2874, ('user', 'mentions_inv', 'tweet'): 1134, ('user', 'mentions_inv', 'user'): 2874, ('user', 'posted', 'reply'): 186602, ('user', 'posted', 'tweet'): 4178, ('user', 'retweeted', 'tweet'): 13710},\n","      metagraph=[('article', 'tweet', 'has_article_inv'), ('tweet', 'claim', 'discusses'), ('tweet', 'article', 'has_article'), ('tweet', 'hashtag', 'has_hashtag'), ('tweet', 'image', 'has_image'), ('tweet', 'user', 'mentions'), ('tweet', 'user', 'posted_inv'), ('tweet', 'user', 'retweeted_inv'), ('tweet', 'reply', 'quote_of_inv'), ('tweet', 'reply', 'reply_to_inv'), ('claim', 'tweet', 'discusses_inv'), ('hashtag', 'tweet', 'has_hashtag_inv'), ('hashtag', 'user', 'has_hashtag_inv'), ('user', 'user', 'follows'), ('user', 'user', 'follows_inv'), ('user', 'user', 'mentions'), ('user', 'user', 'mentions_inv'), ('user', 'hashtag', 'has_hashtag'), ('user', 'tweet', 'mentions_inv'), ('user', 'tweet', 'posted'), ('user', 'tweet', 'retweeted'), ('user', 'reply', 'posted'), ('image', 'tweet', 'has_image_inv'), ('reply', 'user', 'posted_inv'), ('reply', 'tweet', 'quote_of'), ('reply', 'tweet', 'reply_to')])"]},"metadata":{},"execution_count":47}],"source":["if 'dgl_graph' not in globals():\n","    dgl_graph = dataset.to_dgl()\n","dgl_graph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1661168297598,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"4CRDS-HXT7NB","outputId":"ce28426b-1a5e-42e2-f50c-9cec079af9d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Node types in the DGL graph:\n","['article', 'claim', 'hashtag', 'image', 'reply', 'tweet', 'user']\n","\n","Relation types in the DGL graph:\n"]},{"output_type":"execute_result","data":{"text/plain":["[('article', 'has_article_inv', 'tweet'),\n"," ('claim', 'discusses_inv', 'tweet'),\n"," ('hashtag', 'has_hashtag_inv', 'tweet'),\n"," ('hashtag', 'has_hashtag_inv', 'user'),\n"," ('image', 'has_image_inv', 'tweet'),\n"," ('reply', 'posted_inv', 'user'),\n"," ('reply', 'quote_of', 'tweet'),\n"," ('reply', 'reply_to', 'tweet'),\n"," ('tweet', 'discusses', 'claim'),\n"," ('tweet', 'has_article', 'article'),\n"," ('tweet', 'has_hashtag', 'hashtag'),\n"," ('tweet', 'has_image', 'image'),\n"," ('tweet', 'mentions', 'user'),\n"," ('tweet', 'posted_inv', 'user'),\n"," ('tweet', 'quote_of_inv', 'reply'),\n"," ('tweet', 'reply_to_inv', 'reply'),\n"," ('tweet', 'retweeted_inv', 'user'),\n"," ('user', 'follows', 'user'),\n"," ('user', 'follows_inv', 'user'),\n"," ('user', 'has_hashtag', 'hashtag'),\n"," ('user', 'mentions', 'user'),\n"," ('user', 'mentions_inv', 'tweet'),\n"," ('user', 'mentions_inv', 'user'),\n"," ('user', 'posted', 'reply'),\n"," ('user', 'posted', 'tweet'),\n"," ('user', 'retweeted', 'tweet')]"]},"metadata":{},"execution_count":48}],"source":["print('Node types in the DGL graph:')\n","print(dgl_graph.ntypes)\n","print('\\nRelation types in the DGL graph:')\n","dgl_graph.canonical_etypes"]},{"cell_type":"markdown","metadata":{"id":"_iAJWYu0Ibqp"},"source":["## 'user', 'posted', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F27oMow4Id_6","executionInfo":{"status":"ok","timestamp":1661169326900,"user_tz":-480,"elapsed":49222,"user":{"displayName":"胡皓量","userId":"01966224964779321794"}},"outputId":"75823f09-07da-4a32-9cee-faa098ad7e91"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","Training:   0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n","Training:   0%|          | 2/1000 [00:00<00:50, 19.60it/s]\u001b[A\n","Training:   0%|          | 4/1000 [00:00<00:54, 18.43it/s]\u001b[A\n","Training:   1%|          | 6/1000 [00:00<00:55, 17.92it/s]\u001b[A\n","Training:   1%|          | 8/1000 [00:00<00:53, 18.43it/s]\u001b[A\n","Training:   1%|          | 10/1000 [00:00<00:52, 18.90it/s]\u001b[A\n","Training:   1%|          | 12/1000 [00:00<00:51, 19.11it/s]\u001b[A\n","Training:   1%|▏         | 14/1000 [00:00<00:51, 19.32it/s]\u001b[A\n","Training:   2%|▏         | 17/1000 [00:00<00:49, 19.91it/s]\u001b[A\n","Training:   2%|▏         | 20/1000 [00:01<00:48, 20.29it/s]\u001b[A\n","Training:   2%|▏         | 23/1000 [00:01<00:47, 20.50it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   2%|▏         | 23/1000 [00:01<00:47, 20.50it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   3%|▎         | 26/1000 [00:01<00:47, 20.29it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   3%|▎         | 29/1000 [00:01<00:47, 20.43it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   3%|▎         | 32/1000 [00:01<00:47, 20.59it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   4%|▎         | 35/1000 [00:01<00:46, 20.67it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   4%|▍         | 38/1000 [00:01<00:46, 20.68it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   4%|▍         | 41/1000 [00:02<00:46, 20.77it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   4%|▍         | 44/1000 [00:02<00:46, 20.69it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   5%|▍         | 47/1000 [00:02<00:45, 20.82it/s]\u001b[A\n","Training - loss 0.652 - factual_f1 0.226 - misinfo_f1 0.786 - val_loss 0.656 - val_factual_f1 0.052 - val_misinfo_f1 0.978:   5%|▌         | 50/1000 [00:02<00:45, 20.91it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   5%|▌         | 50/1000 [00:02<00:45, 20.91it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   5%|▌         | 53/1000 [00:02<00:45, 20.64it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   6%|▌         | 56/1000 [00:02<00:45, 20.80it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   6%|▌         | 59/1000 [00:02<00:45, 20.73it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   6%|▌         | 62/1000 [00:03<00:45, 20.74it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   6%|▋         | 65/1000 [00:03<00:45, 20.77it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   7%|▋         | 68/1000 [00:03<00:44, 20.83it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   7%|▋         | 71/1000 [00:03<00:44, 20.89it/s]\u001b[A\n","Training - loss 0.602 - factual_f1 0.239 - misinfo_f1 0.839 - val_loss 0.633 - val_factual_f1 0.031 - val_misinfo_f1 0.887:   7%|▋         | 74/1000 [00:03<00:44, 20.80it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:   7%|▋         | 74/1000 [00:03<00:44, 20.80it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:   8%|▊         | 77/1000 [00:03<00:44, 20.57it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:   8%|▊         | 80/1000 [00:03<00:44, 20.66it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:   8%|▊         | 83/1000 [00:04<00:44, 20.75it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:   9%|▊         | 86/1000 [00:04<00:43, 20.85it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:   9%|▉         | 89/1000 [00:04<00:43, 20.95it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:   9%|▉         | 92/1000 [00:04<00:43, 20.91it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:  10%|▉         | 95/1000 [00:04<00:43, 20.90it/s]\u001b[A\n","Training - loss 0.550 - factual_f1 0.274 - misinfo_f1 0.889 - val_loss 0.659 - val_factual_f1 0.038 - val_misinfo_f1 0.875:  10%|▉         | 98/1000 [00:04<00:43, 20.85it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  10%|▉         | 98/1000 [00:04<00:43, 20.85it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  10%|█         | 101/1000 [00:04<00:43, 20.68it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  10%|█         | 104/1000 [00:05<00:43, 20.74it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  11%|█         | 107/1000 [00:05<00:42, 20.77it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  11%|█         | 110/1000 [00:05<00:42, 20.80it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  11%|█▏        | 113/1000 [00:05<00:42, 20.82it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  12%|█▏        | 116/1000 [00:05<00:42, 20.90it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  12%|█▏        | 119/1000 [00:05<00:42, 20.93it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  12%|█▏        | 122/1000 [00:05<00:41, 21.00it/s]\u001b[A\n","Training - loss 0.480 - factual_f1 0.257 - misinfo_f1 0.923 - val_loss 0.723 - val_factual_f1 0.027 - val_misinfo_f1 0.928:  12%|█▎        | 125/1000 [00:06<00:41, 20.94it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  12%|█▎        | 125/1000 [00:06<00:41, 20.94it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  13%|█▎        | 128/1000 [00:06<00:42, 20.56it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  13%|█▎        | 131/1000 [00:06<00:42, 20.61it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  13%|█▎        | 134/1000 [00:06<00:41, 20.63it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  14%|█▎        | 137/1000 [00:06<00:41, 20.61it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  14%|█▍        | 140/1000 [00:06<00:41, 20.84it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  14%|█▍        | 143/1000 [00:06<00:41, 20.86it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  15%|█▍        | 146/1000 [00:07<00:40, 20.90it/s]\u001b[A\n","Training - loss 0.418 - factual_f1 0.244 - misinfo_f1 0.941 - val_loss 0.793 - val_factual_f1 0.005 - val_misinfo_f1 0.960:  15%|█▍        | 149/1000 [00:07<00:40, 20.95it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  15%|█▍        | 149/1000 [00:07<00:40, 20.95it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  15%|█▌        | 152/1000 [00:07<00:41, 20.57it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  16%|█▌        | 155/1000 [00:07<00:40, 20.78it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  16%|█▌        | 158/1000 [00:07<00:40, 20.72it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  16%|█▌        | 161/1000 [00:07<00:40, 20.74it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  16%|█▋        | 164/1000 [00:07<00:40, 20.69it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  17%|█▋        | 167/1000 [00:08<00:40, 20.80it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  17%|█▋        | 170/1000 [00:08<00:39, 20.86it/s]\u001b[A\n","Training - loss 0.356 - factual_f1 0.246 - misinfo_f1 0.950 - val_loss 0.938 - val_factual_f1 0.009 - val_misinfo_f1 0.968:  17%|█▋        | 173/1000 [00:08<00:39, 20.90it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  17%|█▋        | 173/1000 [00:08<00:39, 20.90it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  18%|█▊        | 176/1000 [00:08<00:40, 20.57it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  18%|█▊        | 179/1000 [00:08<00:39, 20.59it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  18%|█▊        | 182/1000 [00:08<00:39, 20.70it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  18%|█▊        | 185/1000 [00:08<00:39, 20.79it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  19%|█▉        | 188/1000 [00:09<00:38, 20.90it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  19%|█▉        | 191/1000 [00:09<00:38, 20.93it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  19%|█▉        | 194/1000 [00:09<00:38, 20.92it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  20%|█▉        | 197/1000 [00:09<00:38, 20.91it/s]\u001b[A\n","Training - loss 0.314 - factual_f1 0.172 - misinfo_f1 0.951 - val_loss 1.093 - val_factual_f1 0.000 - val_misinfo_f1 0.976:  20%|██        | 200/1000 [00:09<00:38, 20.78it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  20%|██        | 200/1000 [00:09<00:38, 20.78it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  20%|██        | 203/1000 [00:09<00:38, 20.49it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  21%|██        | 206/1000 [00:09<00:38, 20.51it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  21%|██        | 209/1000 [00:10<00:38, 20.58it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  21%|██        | 212/1000 [00:10<00:38, 20.70it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  22%|██▏       | 215/1000 [00:10<00:37, 20.84it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  22%|██▏       | 218/1000 [00:10<00:37, 20.89it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  22%|██▏       | 221/1000 [00:10<00:37, 20.94it/s]\u001b[A\n","Training - loss 0.283 - factual_f1 0.270 - misinfo_f1 0.954 - val_loss 1.189 - val_factual_f1 0.000 - val_misinfo_f1 0.978:  22%|██▏       | 224/1000 [00:10<00:36, 21.01it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  22%|██▏       | 224/1000 [00:10<00:36, 21.01it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  23%|██▎       | 227/1000 [00:10<00:37, 20.76it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  23%|██▎       | 230/1000 [00:11<00:36, 20.85it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  23%|██▎       | 233/1000 [00:11<00:36, 20.90it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  24%|██▎       | 236/1000 [00:11<00:36, 20.88it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  24%|██▍       | 239/1000 [00:11<00:36, 20.85it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  24%|██▍       | 242/1000 [00:11<00:36, 20.86it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  24%|██▍       | 245/1000 [00:11<00:36, 20.85it/s]\u001b[A\n","Training - loss 0.271 - factual_f1 0.267 - misinfo_f1 0.953 - val_loss 1.335 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  25%|██▍       | 248/1000 [00:11<00:36, 20.89it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  25%|██▍       | 248/1000 [00:12<00:36, 20.89it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  25%|██▌       | 251/1000 [00:12<00:35, 20.85it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  25%|██▌       | 254/1000 [00:12<00:35, 20.79it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  26%|██▌       | 257/1000 [00:12<00:35, 20.90it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  26%|██▌       | 260/1000 [00:12<00:35, 20.97it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  26%|██▋       | 263/1000 [00:12<00:35, 20.98it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  27%|██▋       | 266/1000 [00:12<00:34, 20.99it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  27%|██▋       | 269/1000 [00:13<00:35, 20.81it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  27%|██▋       | 272/1000 [00:13<00:35, 20.68it/s]\u001b[A\n","Training - loss 0.252 - factual_f1 0.326 - misinfo_f1 0.955 - val_loss 1.389 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  28%|██▊       | 275/1000 [00:13<00:35, 20.69it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  28%|██▊       | 275/1000 [00:13<00:35, 20.69it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  28%|██▊       | 278/1000 [00:13<00:35, 20.38it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  28%|██▊       | 281/1000 [00:13<00:35, 20.49it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  28%|██▊       | 284/1000 [00:13<00:34, 20.63it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  29%|██▊       | 287/1000 [00:13<00:34, 20.69it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  29%|██▉       | 290/1000 [00:14<00:34, 20.73it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  29%|██▉       | 293/1000 [00:14<00:34, 20.79it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  30%|██▉       | 296/1000 [00:14<00:33, 20.78it/s]\u001b[A\n","Training - loss 0.251 - factual_f1 0.306 - misinfo_f1 0.955 - val_loss 1.475 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  30%|██▉       | 299/1000 [00:14<00:33, 20.74it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  30%|██▉       | 299/1000 [00:14<00:33, 20.74it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  30%|███       | 302/1000 [00:14<00:34, 20.33it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  30%|███       | 305/1000 [00:14<00:34, 20.36it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  31%|███       | 308/1000 [00:14<00:33, 20.48it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  31%|███       | 311/1000 [00:15<00:33, 20.51it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  31%|███▏      | 314/1000 [00:15<00:33, 20.62it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  32%|███▏      | 317/1000 [00:15<00:33, 20.59it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  32%|███▏      | 320/1000 [00:15<00:33, 20.55it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.292 - misinfo_f1 0.954 - val_loss 1.617 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  32%|███▏      | 323/1000 [00:15<00:32, 20.68it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  32%|███▏      | 323/1000 [00:15<00:32, 20.68it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  33%|███▎      | 326/1000 [00:15<00:32, 20.57it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  33%|███▎      | 329/1000 [00:15<00:32, 20.56it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  33%|███▎      | 332/1000 [00:16<00:32, 20.69it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  34%|███▎      | 335/1000 [00:16<00:32, 20.77it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  34%|███▍      | 338/1000 [00:16<00:31, 20.73it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  34%|███▍      | 341/1000 [00:16<00:31, 20.69it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  34%|███▍      | 344/1000 [00:16<00:31, 20.75it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  35%|███▍      | 347/1000 [00:16<00:31, 20.78it/s]\u001b[A\n","Training - loss 0.230 - factual_f1 0.335 - misinfo_f1 0.956 - val_loss 1.695 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  35%|███▌      | 350/1000 [00:16<00:31, 20.80it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  35%|███▌      | 350/1000 [00:16<00:31, 20.80it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  35%|███▌      | 353/1000 [00:17<00:31, 20.47it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  36%|███▌      | 356/1000 [00:17<00:31, 20.53it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  36%|███▌      | 359/1000 [00:17<00:31, 20.62it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  36%|███▌      | 362/1000 [00:17<00:30, 20.78it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  36%|███▋      | 365/1000 [00:17<00:30, 20.76it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  37%|███▋      | 368/1000 [00:17<00:30, 20.80it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  37%|███▋      | 371/1000 [00:17<00:30, 20.74it/s]\u001b[A\n","Training - loss 0.224 - factual_f1 0.349 - misinfo_f1 0.958 - val_loss 1.779 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  37%|███▋      | 374/1000 [00:18<00:30, 20.66it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  37%|███▋      | 374/1000 [00:18<00:30, 20.66it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  38%|███▊      | 377/1000 [00:18<00:30, 20.36it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  38%|███▊      | 380/1000 [00:18<00:30, 20.47it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  38%|███▊      | 383/1000 [00:18<00:29, 20.60it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  39%|███▊      | 386/1000 [00:18<00:29, 20.64it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  39%|███▉      | 389/1000 [00:18<00:29, 20.72it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  39%|███▉      | 392/1000 [00:18<00:29, 20.83it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  40%|███▉      | 395/1000 [00:19<00:29, 20.85it/s]\u001b[A\n","Training - loss 0.220 - factual_f1 0.402 - misinfo_f1 0.958 - val_loss 1.822 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  40%|███▉      | 398/1000 [00:19<00:28, 21.02it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  40%|███▉      | 398/1000 [00:19<00:28, 21.02it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  40%|████      | 401/1000 [00:19<00:28, 20.80it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  40%|████      | 404/1000 [00:19<00:28, 20.71it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  41%|████      | 407/1000 [00:19<00:28, 20.69it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  41%|████      | 410/1000 [00:19<00:28, 20.69it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  41%|████▏     | 413/1000 [00:19<00:28, 20.74it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  42%|████▏     | 416/1000 [00:20<00:28, 20.79it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  42%|████▏     | 419/1000 [00:20<00:27, 20.89it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  42%|████▏     | 422/1000 [00:20<00:27, 20.95it/s]\u001b[A\n","Training - loss 0.221 - factual_f1 0.371 - misinfo_f1 0.957 - val_loss 1.745 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  42%|████▎     | 425/1000 [00:20<00:27, 20.87it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  42%|████▎     | 425/1000 [00:20<00:27, 20.87it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  43%|████▎     | 428/1000 [00:20<00:27, 20.65it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  43%|████▎     | 431/1000 [00:20<00:27, 20.78it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  43%|████▎     | 434/1000 [00:20<00:27, 20.90it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  44%|████▎     | 437/1000 [00:21<00:26, 20.91it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  44%|████▍     | 440/1000 [00:21<00:26, 20.83it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  44%|████▍     | 443/1000 [00:21<00:26, 20.84it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  45%|████▍     | 446/1000 [00:21<00:26, 20.77it/s]\u001b[A\n","Training - loss 0.215 - factual_f1 0.421 - misinfo_f1 0.958 - val_loss 1.815 - val_factual_f1 0.000 - val_misinfo_f1 0.980:  45%|████▍     | 449/1000 [00:21<00:26, 20.83it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  45%|████▍     | 449/1000 [00:21<00:26, 20.83it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  45%|████▌     | 452/1000 [00:21<00:26, 20.45it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  46%|████▌     | 455/1000 [00:21<00:26, 20.54it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  46%|████▌     | 458/1000 [00:22<00:26, 20.72it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  46%|████▌     | 461/1000 [00:22<00:25, 20.82it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  46%|████▋     | 464/1000 [00:22<00:25, 20.89it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  47%|████▋     | 467/1000 [00:22<00:25, 20.93it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  47%|████▋     | 470/1000 [00:22<00:25, 20.75it/s]\u001b[A\n","Training - loss 0.211 - factual_f1 0.457 - misinfo_f1 0.961 - val_loss 1.734 - val_factual_f1 0.003 - val_misinfo_f1 0.980:  47%|████▋     | 473/1000 [00:22<00:25, 20.73it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  47%|████▋     | 473/1000 [00:23<00:25, 20.73it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 476/1000 [00:23<00:25, 20.35it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 479/1000 [00:23<00:25, 20.37it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 482/1000 [00:23<00:25, 20.54it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 485/1000 [00:23<00:25, 20.59it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 488/1000 [00:23<00:24, 20.69it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 491/1000 [00:23<00:24, 20.82it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 494/1000 [00:23<00:24, 20.85it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|████▉     | 497/1000 [00:24<00:24, 20.89it/s]\u001b[A\n","Training - loss 0.200 - factual_f1 0.500 - misinfo_f1 0.960 - val_loss 1.660 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|█████     | 500/1000 [00:24<00:23, 20.86it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  50%|█████     | 500/1000 [00:24<00:23, 20.86it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  50%|█████     | 503/1000 [00:24<00:24, 20.52it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  51%|█████     | 506/1000 [00:24<00:24, 20.42it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  51%|█████     | 509/1000 [00:24<00:24, 20.43it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  51%|█████     | 512/1000 [00:24<00:23, 20.49it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  52%|█████▏    | 515/1000 [00:24<00:23, 20.59it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  52%|█████▏    | 518/1000 [00:25<00:23, 20.66it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  52%|█████▏    | 521/1000 [00:25<00:23, 20.74it/s]\u001b[A\n","Training - loss 0.194 - factual_f1 0.473 - misinfo_f1 0.959 - val_loss 1.852 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  52%|█████▏    | 524/1000 [00:25<00:22, 20.76it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  52%|█████▏    | 524/1000 [00:25<00:22, 20.76it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 527/1000 [00:25<00:23, 20.53it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 530/1000 [00:25<00:22, 20.62it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 533/1000 [00:25<00:22, 20.73it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▎    | 536/1000 [00:25<00:22, 20.75it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 539/1000 [00:26<00:22, 20.79it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 542/1000 [00:26<00:22, 20.74it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▍    | 545/1000 [00:26<00:21, 20.84it/s]\u001b[A\n","Training - loss 0.196 - factual_f1 0.498 - misinfo_f1 0.958 - val_loss 1.780 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▍    | 548/1000 [00:26<00:21, 20.91it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  55%|█████▍    | 548/1000 [00:26<00:21, 20.91it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  55%|█████▌    | 551/1000 [00:26<00:21, 20.56it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  55%|█████▌    | 554/1000 [00:26<00:21, 20.66it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  56%|█████▌    | 557/1000 [00:26<00:21, 20.83it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  56%|█████▌    | 560/1000 [00:27<00:21, 20.90it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  56%|█████▋    | 563/1000 [00:27<00:20, 20.82it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  57%|█████▋    | 566/1000 [00:27<00:20, 20.87it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  57%|█████▋    | 569/1000 [00:27<00:20, 20.85it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  57%|█████▋    | 572/1000 [00:27<00:20, 20.77it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.517 - misinfo_f1 0.961 - val_loss 1.834 - val_factual_f1 0.004 - val_misinfo_f1 0.981:  57%|█████▊    | 575/1000 [00:27<00:20, 20.77it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  57%|█████▊    | 575/1000 [00:27<00:20, 20.77it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  58%|█████▊    | 578/1000 [00:27<00:20, 20.46it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  58%|█████▊    | 581/1000 [00:28<00:20, 20.59it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  58%|█████▊    | 584/1000 [00:28<00:20, 20.73it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  59%|█████▊    | 587/1000 [00:28<00:19, 20.80it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  59%|█████▉    | 590/1000 [00:28<00:19, 20.81it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  59%|█████▉    | 593/1000 [00:28<00:19, 20.81it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  60%|█████▉    | 596/1000 [00:28<00:19, 20.90it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.487 - misinfo_f1 0.960 - val_loss 1.927 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  60%|█████▉    | 599/1000 [00:28<00:19, 20.85it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  60%|█████▉    | 599/1000 [00:29<00:19, 20.85it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  60%|██████    | 602/1000 [00:29<00:19, 20.54it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  60%|██████    | 605/1000 [00:29<00:19, 20.61it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  61%|██████    | 608/1000 [00:29<00:19, 20.60it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  61%|██████    | 611/1000 [00:29<00:18, 20.69it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  61%|██████▏   | 614/1000 [00:29<00:18, 20.74it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  62%|██████▏   | 617/1000 [00:29<00:18, 20.82it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  62%|██████▏   | 620/1000 [00:29<00:18, 20.85it/s]\u001b[A\n","Training - loss 0.189 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 1.893 - val_factual_f1 0.025 - val_misinfo_f1 0.979:  62%|██████▏   | 623/1000 [00:30<00:18, 20.86it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  62%|██████▏   | 623/1000 [00:30<00:18, 20.86it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  63%|██████▎   | 626/1000 [00:30<00:18, 20.64it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  63%|██████▎   | 629/1000 [00:30<00:18, 20.54it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  63%|██████▎   | 632/1000 [00:30<00:17, 20.58it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  64%|██████▎   | 635/1000 [00:30<00:17, 20.71it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  64%|██████▍   | 638/1000 [00:30<00:17, 20.71it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  64%|██████▍   | 641/1000 [00:30<00:17, 20.77it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  64%|██████▍   | 644/1000 [00:31<00:17, 20.76it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  65%|██████▍   | 647/1000 [00:31<00:17, 20.76it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.478 - misinfo_f1 0.961 - val_loss 1.829 - val_factual_f1 0.030 - val_misinfo_f1 0.979:  65%|██████▌   | 650/1000 [00:31<00:16, 20.85it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  65%|██████▌   | 650/1000 [00:31<00:16, 20.85it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  65%|██████▌   | 653/1000 [00:31<00:16, 20.63it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  66%|██████▌   | 656/1000 [00:31<00:16, 20.76it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  66%|██████▌   | 659/1000 [00:31<00:16, 20.85it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  66%|██████▌   | 662/1000 [00:31<00:16, 20.96it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  66%|██████▋   | 665/1000 [00:32<00:15, 20.99it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  67%|██████▋   | 668/1000 [00:32<00:15, 21.01it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  67%|██████▋   | 671/1000 [00:32<00:15, 20.96it/s]\u001b[A\n","Training - loss 0.186 - factual_f1 0.543 - misinfo_f1 0.964 - val_loss 1.830 - val_factual_f1 0.006 - val_misinfo_f1 0.979:  67%|██████▋   | 674/1000 [00:32<00:15, 20.88it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  67%|██████▋   | 674/1000 [00:32<00:15, 20.88it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  68%|██████▊   | 677/1000 [00:32<00:15, 20.62it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  68%|██████▊   | 680/1000 [00:32<00:15, 20.71it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  68%|██████▊   | 683/1000 [00:32<00:15, 20.75it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  69%|██████▊   | 686/1000 [00:33<00:15, 20.85it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  69%|██████▉   | 689/1000 [00:33<00:14, 20.84it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  69%|██████▉   | 692/1000 [00:33<00:14, 20.87it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  70%|██████▉   | 695/1000 [00:33<00:14, 20.88it/s]\u001b[A\n","Training - loss 0.185 - factual_f1 0.540 - misinfo_f1 0.963 - val_loss 1.712 - val_factual_f1 0.000 - val_misinfo_f1 0.982:  70%|██████▉   | 698/1000 [00:33<00:14, 20.90it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  70%|██████▉   | 698/1000 [00:33<00:14, 20.90it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  70%|███████   | 701/1000 [00:33<00:14, 20.70it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  70%|███████   | 704/1000 [00:34<00:14, 20.54it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  71%|███████   | 707/1000 [00:34<00:14, 20.58it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  71%|███████   | 710/1000 [00:34<00:14, 20.59it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  71%|███████▏  | 713/1000 [00:34<00:13, 20.68it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  72%|███████▏  | 716/1000 [00:34<00:13, 20.76it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  72%|███████▏  | 719/1000 [00:34<00:13, 20.79it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  72%|███████▏  | 722/1000 [00:34<00:13, 20.80it/s]\u001b[A\n","Training - loss 0.170 - factual_f1 0.587 - misinfo_f1 0.965 - val_loss 1.704 - val_factual_f1 0.004 - val_misinfo_f1 0.980:  72%|███████▎  | 725/1000 [00:35<00:13, 20.83it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  72%|███████▎  | 725/1000 [00:35<00:13, 20.83it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  73%|███████▎  | 728/1000 [00:35<00:13, 20.55it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  73%|███████▎  | 731/1000 [00:35<00:13, 20.65it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  73%|███████▎  | 734/1000 [00:35<00:12, 20.71it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  74%|███████▎  | 737/1000 [00:35<00:12, 20.68it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  74%|███████▍  | 740/1000 [00:35<00:12, 20.67it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  74%|███████▍  | 743/1000 [00:35<00:12, 20.65it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  75%|███████▍  | 746/1000 [00:36<00:12, 20.70it/s]\u001b[A\n","Training - loss 0.164 - factual_f1 0.599 - misinfo_f1 0.966 - val_loss 1.805 - val_factual_f1 0.016 - val_misinfo_f1 0.979:  75%|███████▍  | 749/1000 [00:36<00:12, 20.75it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  75%|███████▍  | 749/1000 [00:36<00:12, 20.75it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  75%|███████▌  | 752/1000 [00:36<00:12, 20.47it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  76%|███████▌  | 755/1000 [00:36<00:11, 20.68it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  76%|███████▌  | 758/1000 [00:36<00:11, 20.73it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  76%|███████▌  | 761/1000 [00:36<00:11, 20.74it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  76%|███████▋  | 764/1000 [00:36<00:11, 20.77it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  77%|███████▋  | 767/1000 [00:37<00:11, 20.82it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  77%|███████▋  | 770/1000 [00:37<00:11, 20.80it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.605 - misinfo_f1 0.969 - val_loss 1.939 - val_factual_f1 0.019 - val_misinfo_f1 0.979:  77%|███████▋  | 773/1000 [00:37<00:10, 20.66it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  77%|███████▋  | 773/1000 [00:37<00:10, 20.66it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  78%|███████▊  | 776/1000 [00:37<00:10, 20.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  78%|███████▊  | 779/1000 [00:37<00:10, 20.48it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  78%|███████▊  | 782/1000 [00:37<00:10, 20.60it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  78%|███████▊  | 785/1000 [00:37<00:10, 20.67it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  79%|███████▉  | 788/1000 [00:38<00:10, 20.77it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  79%|███████▉  | 791/1000 [00:38<00:09, 20.92it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  79%|███████▉  | 794/1000 [00:38<00:09, 20.91it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  80%|███████▉  | 797/1000 [00:38<00:09, 20.91it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.605 - misinfo_f1 0.966 - val_loss 1.870 - val_factual_f1 0.007 - val_misinfo_f1 0.979:  80%|████████  | 800/1000 [00:38<00:09, 20.85it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  80%|████████  | 800/1000 [00:38<00:09, 20.85it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  80%|████████  | 803/1000 [00:38<00:09, 20.48it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  81%|████████  | 806/1000 [00:38<00:09, 20.57it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  81%|████████  | 809/1000 [00:39<00:09, 20.56it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  81%|████████  | 812/1000 [00:39<00:09, 20.58it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  82%|████████▏ | 815/1000 [00:39<00:08, 20.64it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  82%|████████▏ | 818/1000 [00:39<00:08, 20.61it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  82%|████████▏ | 821/1000 [00:39<00:08, 20.82it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.629 - misinfo_f1 0.968 - val_loss 1.774 - val_factual_f1 0.007 - val_misinfo_f1 0.980:  82%|████████▏ | 824/1000 [00:39<00:08, 20.93it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  82%|████████▏ | 824/1000 [00:39<00:08, 20.93it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  83%|████████▎ | 827/1000 [00:39<00:08, 20.70it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  83%|████████▎ | 830/1000 [00:40<00:08, 20.77it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  83%|████████▎ | 833/1000 [00:40<00:07, 20.95it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  84%|████████▎ | 836/1000 [00:40<00:07, 20.87it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  84%|████████▍ | 839/1000 [00:40<00:07, 20.82it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  84%|████████▍ | 842/1000 [00:40<00:07, 20.81it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  84%|████████▍ | 845/1000 [00:40<00:07, 20.77it/s]\u001b[A\n","Training - loss 0.156 - factual_f1 0.630 - misinfo_f1 0.970 - val_loss 1.805 - val_factual_f1 0.004 - val_misinfo_f1 0.977:  85%|████████▍ | 848/1000 [00:40<00:07, 20.70it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  85%|████████▍ | 848/1000 [00:41<00:07, 20.70it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  85%|████████▌ | 851/1000 [00:41<00:07, 20.51it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  85%|████████▌ | 854/1000 [00:41<00:07, 20.46it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  86%|████████▌ | 857/1000 [00:41<00:06, 20.58it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  86%|████████▌ | 860/1000 [00:41<00:06, 20.65it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  86%|████████▋ | 863/1000 [00:41<00:06, 20.69it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  87%|████████▋ | 866/1000 [00:41<00:06, 20.70it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  87%|████████▋ | 869/1000 [00:41<00:06, 20.75it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  87%|████████▋ | 872/1000 [00:42<00:06, 20.67it/s]\u001b[A\n","Training - loss 0.154 - factual_f1 0.638 - misinfo_f1 0.969 - val_loss 1.702 - val_factual_f1 0.007 - val_misinfo_f1 0.978:  88%|████████▊ | 875/1000 [00:42<00:06, 20.65it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  88%|████████▊ | 875/1000 [00:42<00:06, 20.65it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  88%|████████▊ | 878/1000 [00:42<00:05, 20.37it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  88%|████████▊ | 881/1000 [00:42<00:05, 20.44it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  88%|████████▊ | 884/1000 [00:42<00:05, 20.59it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  89%|████████▊ | 887/1000 [00:42<00:05, 20.58it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  89%|████████▉ | 890/1000 [00:42<00:05, 20.63it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  89%|████████▉ | 893/1000 [00:43<00:05, 20.71it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  90%|████████▉ | 896/1000 [00:43<00:04, 20.80it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.610 - misinfo_f1 0.967 - val_loss 1.857 - val_factual_f1 0.015 - val_misinfo_f1 0.978:  90%|████████▉ | 899/1000 [00:43<00:04, 20.81it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  90%|████████▉ | 899/1000 [00:43<00:04, 20.81it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  90%|█████████ | 902/1000 [00:43<00:04, 20.47it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  90%|█████████ | 905/1000 [00:43<00:04, 20.54it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  91%|█████████ | 908/1000 [00:43<00:04, 20.56it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  91%|█████████ | 911/1000 [00:44<00:04, 20.59it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  91%|█████████▏| 914/1000 [00:44<00:04, 20.65it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  92%|█████████▏| 917/1000 [00:44<00:04, 20.66it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  92%|█████████▏| 920/1000 [00:44<00:03, 20.60it/s]\u001b[A\n","Training - loss 0.162 - factual_f1 0.634 - misinfo_f1 0.966 - val_loss 1.901 - val_factual_f1 0.014 - val_misinfo_f1 0.976:  92%|█████████▏| 923/1000 [00:44<00:03, 20.57it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  92%|█████████▏| 923/1000 [00:44<00:03, 20.57it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  93%|█████████▎| 926/1000 [00:44<00:03, 20.45it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  93%|█████████▎| 929/1000 [00:44<00:03, 20.54it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  93%|█████████▎| 932/1000 [00:45<00:03, 20.51it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  94%|█████████▎| 935/1000 [00:45<00:03, 20.43it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  94%|█████████▍| 938/1000 [00:45<00:03, 20.43it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  94%|█████████▍| 941/1000 [00:45<00:02, 20.43it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  94%|█████████▍| 944/1000 [00:45<00:02, 20.49it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  95%|█████████▍| 947/1000 [00:45<00:02, 20.59it/s]\u001b[A\n","Training - loss 0.159 - factual_f1 0.624 - misinfo_f1 0.967 - val_loss 1.895 - val_factual_f1 0.010 - val_misinfo_f1 0.978:  95%|█████████▌| 950/1000 [00:45<00:02, 20.69it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  95%|█████████▌| 950/1000 [00:45<00:02, 20.69it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  95%|█████████▌| 953/1000 [00:46<00:02, 20.54it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  96%|█████████▌| 956/1000 [00:46<00:02, 20.54it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  96%|█████████▌| 959/1000 [00:46<00:01, 20.61it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  96%|█████████▌| 962/1000 [00:46<00:01, 20.66it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  96%|█████████▋| 965/1000 [00:46<00:01, 20.69it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  97%|█████████▋| 968/1000 [00:46<00:01, 20.72it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  97%|█████████▋| 971/1000 [00:46<00:01, 20.64it/s]\u001b[A\n","Training - loss 0.163 - factual_f1 0.589 - misinfo_f1 0.965 - val_loss 1.874 - val_factual_f1 0.037 - val_misinfo_f1 0.978:  97%|█████████▋| 974/1000 [00:47<00:01, 20.67it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977:  97%|█████████▋| 974/1000 [00:47<00:01, 20.67it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977:  98%|█████████▊| 977/1000 [00:47<00:01, 20.37it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977:  98%|█████████▊| 980/1000 [00:47<00:00, 20.51it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977:  98%|█████████▊| 983/1000 [00:47<00:00, 20.49it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977:  99%|█████████▊| 986/1000 [00:47<00:00, 20.53it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977:  99%|█████████▉| 989/1000 [00:47<00:00, 20.52it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977:  99%|█████████▉| 992/1000 [00:47<00:00, 20.45it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977: 100%|█████████▉| 995/1000 [00:48<00:00, 20.62it/s]\u001b[A\n","Training - loss 0.147 - factual_f1 0.647 - misinfo_f1 0.969 - val_loss 1.678 - val_factual_f1 0.007 - val_misinfo_f1 0.977: 100%|██████████| 1000/1000 [00:48<00:00, 20.68it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.0909\n","Misinformation F1: 0.9543\n","Macro-average F1: 0.5226\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rel = ('user', 'posted', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"code","source":["print(epoch_pbar)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42WllMlUYoC7","executionInfo":{"status":"ok","timestamp":1661169195996,"user_tz":-480,"elapsed":348,"user":{"displayName":"胡皓量","userId":"01966224964779321794"}},"outputId":"134ff3ee-581e-4f82-ef90-492db3b51eb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training - loss 0.141 - factual_f1 0.676 - misinfo_f1 0.972 - val_loss 1.317 - val_factual_f1 0.018 - val_misinfo_f1 0.980: 100%|██████████| 1000/1000 [00:56<00:00, 17.57it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"PjeuxchjCDzw"},"source":["## 'reply', 'reply_to', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":714769,"status":"ok","timestamp":1661170056228,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"4Et8bvPZB7oT","outputId":"d6a365f0-46d3-4a49-d16e-91b51e35cfd5"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","Training:   0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\n","Training:   0%|          | 1/1000 [00:00<12:27,  1.34it/s]\u001b[A\n","Training:   0%|          | 2/1000 [00:01<13:19,  1.25it/s]\u001b[A\n","Training:   0%|          | 3/1000 [00:02<13:28,  1.23it/s]\u001b[A\n","Training:   0%|          | 4/1000 [00:03<12:54,  1.29it/s]\u001b[A\n","Training:   0%|          | 5/1000 [00:03<12:25,  1.33it/s]\u001b[A\n","Training:   1%|          | 6/1000 [00:04<12:08,  1.36it/s]\u001b[A\n","Training:   1%|          | 7/1000 [00:05<11:57,  1.38it/s]\u001b[A\n","Training:   1%|          | 8/1000 [00:05<11:48,  1.40it/s]\u001b[A\n","Training:   1%|          | 9/1000 [00:06<11:45,  1.40it/s]\u001b[A\n","Training:   1%|          | 10/1000 [00:07<11:41,  1.41it/s]\u001b[A\n","Training:   1%|          | 11/1000 [00:08<11:42,  1.41it/s]\u001b[A\n","Training:   1%|          | 12/1000 [00:08<11:39,  1.41it/s]\u001b[A\n","Training:   1%|▏         | 13/1000 [00:09<11:37,  1.42it/s]\u001b[A\n","Training:   1%|▏         | 14/1000 [00:10<11:34,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 15/1000 [00:10<11:33,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 16/1000 [00:11<11:32,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 17/1000 [00:12<11:31,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 18/1000 [00:12<11:31,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 19/1000 [00:13<11:30,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 20/1000 [00:14<11:31,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 21/1000 [00:15<11:29,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 22/1000 [00:15<11:29,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 23/1000 [00:16<11:30,  1.42it/s]\u001b[A\n","Training:   2%|▏         | 24/1000 [00:17<11:27,  1.42it/s]\u001b[A\n","Training:   2%|▎         | 25/1000 [00:17<11:24,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   2%|▎         | 25/1000 [00:18<11:24,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 26/1000 [00:18<11:26,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 27/1000 [00:19<11:23,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 28/1000 [00:20<11:23,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 29/1000 [00:20<11:24,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 30/1000 [00:21<11:22,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 31/1000 [00:22<11:21,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 32/1000 [00:22<11:22,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 33/1000 [00:23<11:22,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   3%|▎         | 34/1000 [00:24<11:21,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▎         | 35/1000 [00:24<11:19,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▎         | 36/1000 [00:25<11:19,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▎         | 37/1000 [00:26<11:19,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 38/1000 [00:27<11:21,  1.41it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 39/1000 [00:27<11:19,  1.41it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 40/1000 [00:28<11:17,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 41/1000 [00:29<11:17,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 42/1000 [00:29<11:17,  1.41it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 43/1000 [00:30<11:16,  1.41it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 44/1000 [00:31<11:14,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   4%|▍         | 45/1000 [00:32<11:14,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   5%|▍         | 46/1000 [00:32<11:12,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   5%|▍         | 47/1000 [00:33<11:11,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   5%|▍         | 48/1000 [00:34<11:13,  1.41it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   5%|▍         | 49/1000 [00:34<11:10,  1.42it/s]\u001b[A\n","Training - loss 0.678 - factual_f1 0.191 - misinfo_f1 0.702 - val_loss 0.689 - val_factual_f1 0.025 - val_misinfo_f1 0.536:   5%|▌         | 50/1000 [00:35<11:09,  1.42it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   5%|▌         | 50/1000 [00:36<11:09,  1.42it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   5%|▌         | 51/1000 [00:36<11:10,  1.41it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   5%|▌         | 52/1000 [00:36<11:08,  1.42it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   5%|▌         | 53/1000 [00:37<11:06,  1.42it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   5%|▌         | 54/1000 [00:38<11:06,  1.42it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 55/1000 [00:39<11:06,  1.42it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 56/1000 [00:39<11:39,  1.35it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 57/1000 [00:40<11:35,  1.36it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 58/1000 [00:41<11:27,  1.37it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 59/1000 [00:42<11:26,  1.37it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 60/1000 [00:42<11:49,  1.33it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 61/1000 [00:43<11:32,  1.36it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▌         | 62/1000 [00:44<11:22,  1.38it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▋         | 63/1000 [00:44<11:13,  1.39it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▋         | 64/1000 [00:45<11:08,  1.40it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   6%|▋         | 65/1000 [00:46<11:02,  1.41it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 66/1000 [00:47<11:02,  1.41it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 67/1000 [00:47<11:02,  1.41it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 68/1000 [00:48<10:59,  1.41it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 69/1000 [00:49<10:58,  1.41it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 70/1000 [00:49<10:56,  1.42it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 71/1000 [00:50<11:00,  1.41it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 72/1000 [00:51<12:03,  1.28it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 73/1000 [00:52<13:47,  1.12it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   7%|▋         | 74/1000 [00:53<13:24,  1.15it/s]\u001b[A\n","Training - loss 0.635 - factual_f1 0.216 - misinfo_f1 0.817 - val_loss 0.663 - val_factual_f1 0.024 - val_misinfo_f1 0.825:   8%|▊         | 75/1000 [00:54<12:57,  1.19it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 75/1000 [00:55<12:57,  1.19it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 76/1000 [00:55<12:48,  1.20it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 77/1000 [00:55<12:12,  1.26it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 78/1000 [00:56<11:48,  1.30it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 79/1000 [00:57<11:29,  1.34it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 80/1000 [00:58<11:30,  1.33it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 81/1000 [00:58<11:29,  1.33it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 82/1000 [00:59<11:38,  1.31it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 83/1000 [01:00<12:35,  1.21it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 84/1000 [01:01<12:51,  1.19it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   8%|▊         | 85/1000 [01:02<13:18,  1.15it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▊         | 86/1000 [01:03<13:39,  1.12it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▊         | 87/1000 [01:04<13:00,  1.17it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▉         | 88/1000 [01:04<12:32,  1.21it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▉         | 89/1000 [01:05<12:02,  1.26it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▉         | 90/1000 [01:06<11:39,  1.30it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▉         | 91/1000 [01:06<11:20,  1.33it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▉         | 92/1000 [01:07<11:10,  1.35it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▉         | 93/1000 [01:08<11:06,  1.36it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:   9%|▉         | 94/1000 [01:09<11:06,  1.36it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:  10%|▉         | 95/1000 [01:09<11:03,  1.36it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:  10%|▉         | 96/1000 [01:10<11:13,  1.34it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:  10%|▉         | 97/1000 [01:11<11:02,  1.36it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:  10%|▉         | 98/1000 [01:12<10:53,  1.38it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:  10%|▉         | 99/1000 [01:12<10:45,  1.40it/s]\u001b[A\n","Training - loss 0.587 - factual_f1 0.202 - misinfo_f1 0.895 - val_loss 0.621 - val_factual_f1 0.038 - val_misinfo_f1 0.881:  10%|█         | 100/1000 [01:13<10:42,  1.40it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  10%|█         | 100/1000 [01:14<10:42,  1.40it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  10%|█         | 101/1000 [01:14<10:50,  1.38it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  10%|█         | 102/1000 [01:14<10:49,  1.38it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  10%|█         | 103/1000 [01:15<10:46,  1.39it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  10%|█         | 104/1000 [01:16<10:40,  1.40it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  10%|█         | 105/1000 [01:17<10:35,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█         | 106/1000 [01:17<10:34,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█         | 107/1000 [01:18<10:33,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█         | 108/1000 [01:19<10:39,  1.39it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█         | 109/1000 [01:19<10:44,  1.38it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█         | 110/1000 [01:20<10:48,  1.37it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█         | 111/1000 [01:21<10:41,  1.38it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█         | 112/1000 [01:22<10:36,  1.40it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█▏        | 113/1000 [01:22<10:32,  1.40it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  11%|█▏        | 114/1000 [01:23<10:28,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 115/1000 [01:24<10:29,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 116/1000 [01:24<10:24,  1.42it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 117/1000 [01:25<10:20,  1.42it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 118/1000 [01:26<10:21,  1.42it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 119/1000 [01:26<10:21,  1.42it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 120/1000 [01:27<10:21,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 121/1000 [01:28<10:20,  1.42it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 122/1000 [01:29<10:20,  1.42it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 123/1000 [01:29<10:21,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▏        | 124/1000 [01:30<10:19,  1.41it/s]\u001b[A\n","Training - loss 0.529 - factual_f1 0.226 - misinfo_f1 0.902 - val_loss 0.553 - val_factual_f1 0.087 - val_misinfo_f1 0.961:  12%|█▎        | 125/1000 [01:31<10:18,  1.41it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  12%|█▎        | 125/1000 [01:31<10:18,  1.41it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 126/1000 [01:32<10:36,  1.37it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 127/1000 [01:32<11:30,  1.27it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 128/1000 [01:34<13:08,  1.11it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 129/1000 [01:35<13:36,  1.07it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 130/1000 [01:36<13:39,  1.06it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 131/1000 [01:36<12:43,  1.14it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 132/1000 [01:37<11:55,  1.21it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 133/1000 [01:38<11:22,  1.27it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  13%|█▎        | 134/1000 [01:38<11:01,  1.31it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▎        | 135/1000 [01:39<10:45,  1.34it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▎        | 136/1000 [01:40<10:34,  1.36it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▎        | 137/1000 [01:41<10:27,  1.38it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 138/1000 [01:41<10:23,  1.38it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 139/1000 [01:42<10:23,  1.38it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 140/1000 [01:43<10:17,  1.39it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 141/1000 [01:43<10:10,  1.41it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 142/1000 [01:44<10:07,  1.41it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 143/1000 [01:45<10:05,  1.42it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 144/1000 [01:45<10:04,  1.42it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  14%|█▍        | 145/1000 [01:46<10:03,  1.42it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  15%|█▍        | 146/1000 [01:47<10:03,  1.41it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  15%|█▍        | 147/1000 [01:48<10:01,  1.42it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  15%|█▍        | 148/1000 [01:48<10:02,  1.41it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  15%|█▍        | 149/1000 [01:49<10:01,  1.41it/s]\u001b[A\n","Training - loss 0.459 - factual_f1 0.171 - misinfo_f1 0.938 - val_loss 0.458 - val_factual_f1 0.089 - val_misinfo_f1 0.985:  15%|█▌        | 150/1000 [01:50<10:05,  1.40it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  15%|█▌        | 150/1000 [01:50<10:05,  1.40it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  15%|█▌        | 151/1000 [01:50<10:05,  1.40it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  15%|█▌        | 152/1000 [01:51<10:02,  1.41it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  15%|█▌        | 153/1000 [01:52<10:02,  1.41it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  15%|█▌        | 154/1000 [01:53<10:02,  1.40it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 155/1000 [01:53<09:57,  1.41it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 156/1000 [01:54<09:57,  1.41it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 157/1000 [01:55<09:55,  1.41it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 158/1000 [01:55<09:54,  1.42it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 159/1000 [01:56<09:52,  1.42it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 160/1000 [01:57<09:49,  1.43it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 161/1000 [01:57<09:47,  1.43it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▌        | 162/1000 [01:58<09:45,  1.43it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▋        | 163/1000 [01:59<09:44,  1.43it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▋        | 164/1000 [02:00<09:46,  1.43it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  16%|█▋        | 165/1000 [02:00<09:44,  1.43it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 166/1000 [02:01<09:45,  1.43it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 167/1000 [02:02<09:45,  1.42it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 168/1000 [02:03<10:10,  1.36it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 169/1000 [02:03<10:02,  1.38it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 170/1000 [02:04<09:57,  1.39it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 171/1000 [02:05<09:52,  1.40it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 172/1000 [02:05<09:48,  1.41it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 173/1000 [02:06<09:43,  1.42it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  17%|█▋        | 174/1000 [02:07<09:43,  1.41it/s]\u001b[A\n","Training - loss 0.400 - factual_f1 0.107 - misinfo_f1 0.946 - val_loss 0.392 - val_factual_f1 0.076 - val_misinfo_f1 0.987:  18%|█▊        | 175/1000 [02:07<09:40,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 175/1000 [02:08<09:40,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 176/1000 [02:08<09:43,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 177/1000 [02:09<09:42,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 178/1000 [02:10<09:41,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 179/1000 [02:10<09:39,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 180/1000 [02:11<09:37,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 181/1000 [02:12<09:38,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 182/1000 [02:12<09:38,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 183/1000 [02:13<09:36,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 184/1000 [02:14<09:36,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  18%|█▊        | 185/1000 [02:14<09:34,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▊        | 186/1000 [02:15<09:33,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▊        | 187/1000 [02:16<09:40,  1.40it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▉        | 188/1000 [02:17<09:38,  1.40it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▉        | 189/1000 [02:17<09:35,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▉        | 190/1000 [02:18<09:35,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▉        | 191/1000 [02:19<09:33,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▉        | 192/1000 [02:19<09:34,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▉        | 193/1000 [02:20<09:32,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  19%|█▉        | 194/1000 [02:21<09:31,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  20%|█▉        | 195/1000 [02:22<09:32,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  20%|█▉        | 196/1000 [02:22<09:30,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  20%|█▉        | 197/1000 [02:23<09:28,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  20%|█▉        | 198/1000 [02:24<09:26,  1.42it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  20%|█▉        | 199/1000 [02:24<09:27,  1.41it/s]\u001b[A\n","Training - loss 0.354 - factual_f1 0.095 - misinfo_f1 0.948 - val_loss 0.323 - val_factual_f1 0.005 - val_misinfo_f1 0.986:  20%|██        | 200/1000 [02:25<09:28,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  20%|██        | 200/1000 [02:26<09:28,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  20%|██        | 201/1000 [02:26<09:28,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  20%|██        | 202/1000 [02:27<09:27,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  20%|██        | 203/1000 [02:27<09:29,  1.40it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  20%|██        | 204/1000 [02:28<09:27,  1.40it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  20%|██        | 205/1000 [02:29<09:26,  1.40it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██        | 206/1000 [02:29<09:28,  1.40it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██        | 207/1000 [02:30<09:26,  1.40it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██        | 208/1000 [02:31<09:22,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██        | 209/1000 [02:32<09:21,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██        | 210/1000 [02:32<09:21,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██        | 211/1000 [02:33<09:20,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██        | 212/1000 [02:34<09:18,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██▏       | 213/1000 [02:34<09:19,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  21%|██▏       | 214/1000 [02:35<09:18,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 215/1000 [02:36<09:16,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 216/1000 [02:37<09:16,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 217/1000 [02:37<09:16,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 218/1000 [02:38<09:14,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 219/1000 [02:39<09:11,  1.42it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 220/1000 [02:39<09:12,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 221/1000 [02:40<09:11,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 222/1000 [02:41<09:10,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 223/1000 [02:41<09:12,  1.41it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▏       | 224/1000 [02:42<09:13,  1.40it/s]\u001b[A\n","Training - loss 0.326 - factual_f1 0.130 - misinfo_f1 0.947 - val_loss 0.264 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  22%|██▎       | 225/1000 [02:43<09:10,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  22%|██▎       | 225/1000 [02:44<09:10,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 226/1000 [02:44<09:10,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 227/1000 [02:44<09:10,  1.40it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 228/1000 [02:45<09:08,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 229/1000 [02:46<09:08,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 230/1000 [02:46<09:07,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 231/1000 [02:47<09:05,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 232/1000 [02:48<09:03,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 233/1000 [02:49<09:01,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  23%|██▎       | 234/1000 [02:49<09:00,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▎       | 235/1000 [02:50<08:57,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▎       | 236/1000 [02:51<08:58,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▎       | 237/1000 [02:51<08:58,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 238/1000 [02:52<08:57,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 239/1000 [02:53<08:59,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 240/1000 [02:54<08:56,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 241/1000 [02:54<08:55,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 242/1000 [02:55<08:55,  1.42it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 243/1000 [02:56<08:56,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 244/1000 [02:56<08:56,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  24%|██▍       | 245/1000 [02:57<08:55,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  25%|██▍       | 246/1000 [02:58<08:54,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  25%|██▍       | 247/1000 [02:59<08:55,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  25%|██▍       | 248/1000 [02:59<08:52,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  25%|██▍       | 249/1000 [03:00<08:51,  1.41it/s]\u001b[A\n","Training - loss 0.297 - factual_f1 0.094 - misinfo_f1 0.951 - val_loss 0.226 - val_factual_f1 0.000 - val_misinfo_f1 0.988:  25%|██▌       | 250/1000 [03:01<08:52,  1.41it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  25%|██▌       | 250/1000 [03:01<08:52,  1.41it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  25%|██▌       | 251/1000 [03:01<08:52,  1.41it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  25%|██▌       | 252/1000 [03:02<08:51,  1.41it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  25%|██▌       | 253/1000 [03:03<08:49,  1.41it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  25%|██▌       | 254/1000 [03:03<08:47,  1.41it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 255/1000 [03:04<08:44,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 256/1000 [03:05<08:45,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 257/1000 [03:06<08:44,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 258/1000 [03:06<08:42,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 259/1000 [03:07<08:42,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 260/1000 [03:08<08:42,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 261/1000 [03:08<08:41,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▌       | 262/1000 [03:09<08:38,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▋       | 263/1000 [03:10<08:37,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▋       | 264/1000 [03:10<08:36,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  26%|██▋       | 265/1000 [03:11<08:36,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 266/1000 [03:12<08:36,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 267/1000 [03:13<08:34,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 268/1000 [03:13<08:34,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 269/1000 [03:14<08:33,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 270/1000 [03:15<08:34,  1.42it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 271/1000 [03:16<08:59,  1.35it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 272/1000 [03:16<08:51,  1.37it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 273/1000 [03:17<08:44,  1.38it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  27%|██▋       | 274/1000 [03:18<08:40,  1.39it/s]\u001b[A\n","Training - loss 0.285 - factual_f1 0.098 - misinfo_f1 0.950 - val_loss 0.194 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  28%|██▊       | 275/1000 [03:18<08:58,  1.35it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 275/1000 [03:19<08:58,  1.35it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 276/1000 [03:19<08:48,  1.37it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 277/1000 [03:20<08:44,  1.38it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 278/1000 [03:21<08:40,  1.39it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 279/1000 [03:21<08:36,  1.40it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 280/1000 [03:22<08:32,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 281/1000 [03:23<08:55,  1.34it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 282/1000 [03:24<09:00,  1.33it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 283/1000 [03:24<08:49,  1.35it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 284/1000 [03:25<08:42,  1.37it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  28%|██▊       | 285/1000 [03:26<08:36,  1.38it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▊       | 286/1000 [03:26<08:32,  1.39it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▊       | 287/1000 [03:27<08:30,  1.40it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▉       | 288/1000 [03:28<08:28,  1.40it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▉       | 289/1000 [03:29<08:25,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▉       | 290/1000 [03:29<08:23,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▉       | 291/1000 [03:30<08:22,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▉       | 292/1000 [03:31<08:21,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▉       | 293/1000 [03:31<08:21,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  29%|██▉       | 294/1000 [03:32<08:21,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  30%|██▉       | 295/1000 [03:33<08:20,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  30%|██▉       | 296/1000 [03:33<08:19,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  30%|██▉       | 297/1000 [03:34<08:17,  1.41it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  30%|██▉       | 298/1000 [03:35<08:15,  1.42it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  30%|██▉       | 299/1000 [03:36<08:15,  1.42it/s]\u001b[A\n","Training - loss 0.270 - factual_f1 0.165 - misinfo_f1 0.950 - val_loss 0.186 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  30%|███       | 300/1000 [03:36<08:15,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  30%|███       | 300/1000 [03:37<08:15,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  30%|███       | 301/1000 [03:37<08:15,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  30%|███       | 302/1000 [03:38<08:13,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  30%|███       | 303/1000 [03:38<08:12,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  30%|███       | 304/1000 [03:39<08:12,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  30%|███       | 305/1000 [03:40<08:09,  1.42it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███       | 306/1000 [03:41<08:11,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███       | 307/1000 [03:41<08:11,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███       | 308/1000 [03:42<08:11,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███       | 309/1000 [03:43<08:10,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███       | 310/1000 [03:43<08:11,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███       | 311/1000 [03:44<08:08,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███       | 312/1000 [03:45<08:05,  1.42it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███▏      | 313/1000 [03:46<08:08,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  31%|███▏      | 314/1000 [03:46<08:08,  1.40it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 315/1000 [03:47<08:08,  1.40it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 316/1000 [03:48<08:06,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 317/1000 [03:48<08:03,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 318/1000 [03:49<08:03,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 319/1000 [03:50<08:02,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 320/1000 [03:50<08:01,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 321/1000 [03:51<07:58,  1.42it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 322/1000 [03:52<07:59,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 323/1000 [03:53<07:59,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▏      | 324/1000 [03:53<07:58,  1.41it/s]\u001b[A\n","Training - loss 0.258 - factual_f1 0.223 - misinfo_f1 0.954 - val_loss 0.181 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▎      | 325/1000 [03:54<07:57,  1.41it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  32%|███▎      | 325/1000 [03:55<07:57,  1.41it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 326/1000 [03:55<07:57,  1.41it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 327/1000 [03:55<08:00,  1.40it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 328/1000 [03:56<07:57,  1.41it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 329/1000 [03:57<07:54,  1.41it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 330/1000 [03:58<07:51,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 331/1000 [03:58<07:49,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 332/1000 [03:59<07:49,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 333/1000 [04:00<07:48,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  33%|███▎      | 334/1000 [04:00<07:49,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▎      | 335/1000 [04:01<07:47,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▎      | 336/1000 [04:02<07:46,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▎      | 337/1000 [04:02<07:45,  1.43it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 338/1000 [04:03<07:46,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 339/1000 [04:04<07:43,  1.43it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 340/1000 [04:05<07:43,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 341/1000 [04:05<07:41,  1.43it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 342/1000 [04:06<07:40,  1.43it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 343/1000 [04:07<07:41,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 344/1000 [04:07<07:41,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  34%|███▍      | 345/1000 [04:08<07:41,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  35%|███▍      | 346/1000 [04:09<07:40,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  35%|███▍      | 347/1000 [04:10<07:38,  1.42it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  35%|███▍      | 348/1000 [04:10<07:37,  1.43it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  35%|███▍      | 349/1000 [04:11<07:36,  1.43it/s]\u001b[A\n","Training - loss 0.272 - factual_f1 0.152 - misinfo_f1 0.951 - val_loss 0.178 - val_factual_f1 0.000 - val_misinfo_f1 0.983:  35%|███▌      | 350/1000 [04:12<07:38,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  35%|███▌      | 350/1000 [04:12<07:38,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  35%|███▌      | 351/1000 [04:12<07:39,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  35%|███▌      | 352/1000 [04:13<07:39,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  35%|███▌      | 353/1000 [04:14<07:37,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  35%|███▌      | 354/1000 [04:14<07:35,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 355/1000 [04:15<07:33,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 356/1000 [04:16<07:34,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 357/1000 [04:17<07:34,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 358/1000 [04:17<07:31,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 359/1000 [04:18<07:31,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 360/1000 [04:19<07:30,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 361/1000 [04:19<07:30,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▌      | 362/1000 [04:20<07:30,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▋      | 363/1000 [04:21<07:30,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▋      | 364/1000 [04:22<07:30,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  36%|███▋      | 365/1000 [04:22<07:29,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 366/1000 [04:23<07:28,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 367/1000 [04:24<07:27,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 368/1000 [04:24<07:24,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 369/1000 [04:25<07:25,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 370/1000 [04:26<07:24,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 371/1000 [04:26<07:23,  1.42it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 372/1000 [04:27<07:24,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 373/1000 [04:28<07:24,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  37%|███▋      | 374/1000 [04:29<07:23,  1.41it/s]\u001b[A\n","Training - loss 0.265 - factual_f1 0.187 - misinfo_f1 0.953 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.990:  38%|███▊      | 375/1000 [04:29<07:23,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 375/1000 [04:30<07:23,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 376/1000 [04:30<07:21,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 377/1000 [04:31<07:22,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 378/1000 [04:31<07:20,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 379/1000 [04:32<07:20,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 380/1000 [04:33<07:17,  1.42it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 381/1000 [04:34<07:17,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 382/1000 [04:34<07:16,  1.42it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 383/1000 [04:35<07:33,  1.36it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 384/1000 [04:36<07:28,  1.37it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  38%|███▊      | 385/1000 [04:36<07:23,  1.39it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▊      | 386/1000 [04:37<07:20,  1.39it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▊      | 387/1000 [04:38<07:17,  1.40it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▉      | 388/1000 [04:39<07:15,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▉      | 389/1000 [04:39<07:13,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▉      | 390/1000 [04:40<07:11,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▉      | 391/1000 [04:41<07:09,  1.42it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▉      | 392/1000 [04:41<07:09,  1.42it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▉      | 393/1000 [04:42<07:10,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  39%|███▉      | 394/1000 [04:43<07:09,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  40%|███▉      | 395/1000 [04:44<07:08,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  40%|███▉      | 396/1000 [04:44<07:07,  1.41it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  40%|███▉      | 397/1000 [04:45<07:05,  1.42it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  40%|███▉      | 398/1000 [04:46<07:04,  1.42it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  40%|███▉      | 399/1000 [04:46<07:03,  1.42it/s]\u001b[A\n","Training - loss 0.248 - factual_f1 0.257 - misinfo_f1 0.954 - val_loss 0.144 - val_factual_f1 0.050 - val_misinfo_f1 0.989:  40%|████      | 400/1000 [04:47<07:02,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  40%|████      | 400/1000 [04:48<07:02,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  40%|████      | 401/1000 [04:48<07:03,  1.41it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  40%|████      | 402/1000 [04:48<07:01,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  40%|████      | 403/1000 [04:49<06:59,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  40%|████      | 404/1000 [04:50<07:00,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  40%|████      | 405/1000 [04:51<06:59,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████      | 406/1000 [04:51<06:59,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████      | 407/1000 [04:52<06:59,  1.41it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████      | 408/1000 [04:53<06:58,  1.41it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████      | 409/1000 [04:53<06:57,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████      | 410/1000 [04:54<06:55,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████      | 411/1000 [04:55<06:54,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████      | 412/1000 [04:55<06:53,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████▏     | 413/1000 [04:56<06:53,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  41%|████▏     | 414/1000 [04:57<06:54,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 415/1000 [04:58<06:53,  1.41it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 416/1000 [04:58<06:55,  1.40it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 417/1000 [04:59<06:54,  1.41it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 418/1000 [05:00<06:52,  1.41it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 419/1000 [05:00<06:49,  1.42it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 420/1000 [05:01<07:12,  1.34it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 421/1000 [05:02<07:17,  1.32it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 422/1000 [05:03<07:08,  1.35it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 423/1000 [05:03<07:01,  1.37it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▏     | 424/1000 [05:04<06:58,  1.38it/s]\u001b[A\n","Training - loss 0.239 - factual_f1 0.314 - misinfo_f1 0.955 - val_loss 0.150 - val_factual_f1 0.000 - val_misinfo_f1 0.987:  42%|████▎     | 425/1000 [05:05<06:55,  1.39it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  42%|████▎     | 425/1000 [05:06<06:55,  1.39it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 426/1000 [05:06<06:52,  1.39it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 427/1000 [05:06<06:50,  1.40it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 428/1000 [05:07<06:47,  1.40it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 429/1000 [05:08<06:44,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 430/1000 [05:08<06:43,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 431/1000 [05:09<06:43,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 432/1000 [05:10<06:44,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 433/1000 [05:11<06:42,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  43%|████▎     | 434/1000 [05:11<06:43,  1.40it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▎     | 435/1000 [05:12<06:40,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▎     | 436/1000 [05:13<06:38,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▎     | 437/1000 [05:13<06:38,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 438/1000 [05:14<06:38,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 439/1000 [05:15<06:36,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 440/1000 [05:16<06:36,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 441/1000 [05:16<06:35,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 442/1000 [05:17<06:34,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 443/1000 [05:18<06:33,  1.41it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 444/1000 [05:18<06:31,  1.42it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  44%|████▍     | 445/1000 [05:19<06:30,  1.42it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  45%|████▍     | 446/1000 [05:20<06:29,  1.42it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  45%|████▍     | 447/1000 [05:20<06:29,  1.42it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  45%|████▍     | 448/1000 [05:21<06:29,  1.42it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  45%|████▍     | 449/1000 [05:22<06:28,  1.42it/s]\u001b[A\n","Training - loss 0.229 - factual_f1 0.381 - misinfo_f1 0.957 - val_loss 0.153 - val_factual_f1 0.000 - val_misinfo_f1 0.986:  45%|████▌     | 450/1000 [05:23<06:29,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  45%|████▌     | 450/1000 [05:23<06:29,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  45%|████▌     | 451/1000 [05:23<06:29,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  45%|████▌     | 452/1000 [05:24<06:30,  1.40it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  45%|████▌     | 453/1000 [05:25<06:29,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  45%|████▌     | 454/1000 [05:25<06:28,  1.40it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 455/1000 [05:26<06:27,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 456/1000 [05:27<06:26,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 457/1000 [05:28<06:25,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 458/1000 [05:28<06:22,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 459/1000 [05:29<06:21,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 460/1000 [05:30<06:21,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 461/1000 [05:30<06:19,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▌     | 462/1000 [05:31<06:19,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▋     | 463/1000 [05:32<06:17,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▋     | 464/1000 [05:33<06:17,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  46%|████▋     | 465/1000 [05:33<06:17,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 466/1000 [05:34<06:18,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 467/1000 [05:35<06:16,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 468/1000 [05:35<06:15,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 469/1000 [05:36<06:38,  1.33it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 470/1000 [05:37<06:44,  1.31it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 471/1000 [05:38<06:45,  1.31it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 472/1000 [05:39<06:44,  1.31it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 473/1000 [05:39<06:34,  1.34it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  47%|████▋     | 474/1000 [05:40<06:28,  1.35it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.381 - misinfo_f1 0.958 - val_loss 0.158 - val_factual_f1 0.000 - val_misinfo_f1 0.984:  48%|████▊     | 475/1000 [05:41<06:23,  1.37it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 475/1000 [05:41<06:23,  1.37it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 476/1000 [05:41<06:19,  1.38it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 477/1000 [05:42<06:18,  1.38it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 478/1000 [05:43<06:14,  1.39it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 479/1000 [05:43<06:12,  1.40it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 480/1000 [05:44<06:10,  1.40it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 481/1000 [05:45<06:08,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 482/1000 [05:46<06:06,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 483/1000 [05:46<06:04,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 484/1000 [05:47<06:02,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  48%|████▊     | 485/1000 [05:48<06:01,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▊     | 486/1000 [05:48<06:01,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▊     | 487/1000 [05:49<06:00,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 488/1000 [05:50<05:59,  1.43it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 489/1000 [05:51<05:59,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 490/1000 [05:51<05:59,  1.42it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 491/1000 [05:52<06:14,  1.36it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 492/1000 [05:53<06:07,  1.38it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 493/1000 [05:53<06:04,  1.39it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  49%|████▉     | 494/1000 [05:54<06:05,  1.39it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|████▉     | 495/1000 [05:55<06:03,  1.39it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|████▉     | 496/1000 [05:56<06:00,  1.40it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|████▉     | 497/1000 [05:56<05:58,  1.40it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|████▉     | 498/1000 [05:57<05:56,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|████▉     | 499/1000 [05:58<05:54,  1.41it/s]\u001b[A\n","Training - loss 0.222 - factual_f1 0.374 - misinfo_f1 0.956 - val_loss 0.170 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  50%|█████     | 500/1000 [05:58<05:52,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  50%|█████     | 500/1000 [05:59<05:52,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  50%|█████     | 501/1000 [05:59<05:52,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  50%|█████     | 502/1000 [06:00<05:52,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  50%|█████     | 503/1000 [06:01<05:50,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  50%|█████     | 504/1000 [06:01<05:53,  1.40it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  50%|█████     | 505/1000 [06:02<05:51,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████     | 506/1000 [06:03<05:51,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████     | 507/1000 [06:03<05:50,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████     | 508/1000 [06:04<05:49,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████     | 509/1000 [06:05<05:49,  1.40it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████     | 510/1000 [06:06<05:48,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████     | 511/1000 [06:06<05:47,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████     | 512/1000 [06:07<05:45,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████▏    | 513/1000 [06:08<05:44,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  51%|█████▏    | 514/1000 [06:08<05:42,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 515/1000 [06:09<05:40,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 516/1000 [06:10<05:39,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 517/1000 [06:10<05:39,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 518/1000 [06:11<05:39,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 519/1000 [06:12<05:39,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 520/1000 [06:13<05:39,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 521/1000 [06:13<05:38,  1.41it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 522/1000 [06:14<05:37,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 523/1000 [06:15<05:36,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▏    | 524/1000 [06:15<05:35,  1.42it/s]\u001b[A\n","Training - loss 0.212 - factual_f1 0.430 - misinfo_f1 0.961 - val_loss 0.171 - val_factual_f1 0.021 - val_misinfo_f1 0.981:  52%|█████▎    | 525/1000 [06:16<05:33,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  52%|█████▎    | 525/1000 [06:17<05:33,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 526/1000 [06:17<05:32,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 527/1000 [06:17<05:32,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 528/1000 [06:18<05:32,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 529/1000 [06:19<05:31,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 530/1000 [06:20<05:31,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 531/1000 [06:20<05:31,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 532/1000 [06:21<05:30,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 533/1000 [06:22<05:29,  1.42it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  53%|█████▎    | 534/1000 [06:22<05:29,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▎    | 535/1000 [06:23<05:29,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▎    | 536/1000 [06:24<05:29,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▎    | 537/1000 [06:25<05:28,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 538/1000 [06:25<05:29,  1.40it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 539/1000 [06:26<05:26,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 540/1000 [06:27<05:26,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 541/1000 [06:27<05:26,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 542/1000 [06:28<05:25,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 543/1000 [06:29<05:24,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  54%|█████▍    | 544/1000 [06:30<05:24,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▍    | 545/1000 [06:30<05:23,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▍    | 546/1000 [06:31<05:22,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▍    | 547/1000 [06:32<05:21,  1.41it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▍    | 548/1000 [06:32<05:22,  1.40it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▍    | 549/1000 [06:33<05:21,  1.40it/s]\u001b[A\n","Training - loss 0.231 - factual_f1 0.394 - misinfo_f1 0.957 - val_loss 0.166 - val_factual_f1 0.000 - val_misinfo_f1 0.981:  55%|█████▌    | 550/1000 [06:34<05:20,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  55%|█████▌    | 550/1000 [06:35<05:20,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  55%|█████▌    | 551/1000 [06:35<05:19,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  55%|█████▌    | 552/1000 [06:35<05:18,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  55%|█████▌    | 553/1000 [06:36<05:17,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  55%|█████▌    | 554/1000 [06:37<05:17,  1.40it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 555/1000 [06:37<05:16,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 556/1000 [06:38<05:15,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 557/1000 [06:39<05:13,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 558/1000 [06:39<05:12,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 559/1000 [06:40<05:11,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 560/1000 [06:41<05:11,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 561/1000 [06:42<05:09,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▌    | 562/1000 [06:42<05:09,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▋    | 563/1000 [06:43<05:08,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▋    | 564/1000 [06:44<05:07,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  56%|█████▋    | 565/1000 [06:44<05:07,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 566/1000 [06:45<05:06,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 567/1000 [06:46<05:05,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 568/1000 [06:47<05:04,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 569/1000 [06:47<05:02,  1.43it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 570/1000 [06:48<05:01,  1.43it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 571/1000 [06:49<05:03,  1.41it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 572/1000 [06:49<05:02,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 573/1000 [06:50<05:00,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▋    | 574/1000 [06:51<04:59,  1.42it/s]\u001b[A\n","Training - loss 0.214 - factual_f1 0.420 - misinfo_f1 0.960 - val_loss 0.156 - val_factual_f1 0.008 - val_misinfo_f1 0.984:  57%|█████▊    | 575/1000 [06:51<04:59,  1.42it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  57%|█████▊    | 575/1000 [06:52<04:59,  1.42it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 576/1000 [06:52<04:59,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 577/1000 [06:53<05:00,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 578/1000 [06:54<04:58,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 579/1000 [06:54<04:57,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 580/1000 [06:55<04:56,  1.42it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 581/1000 [06:56<04:55,  1.42it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 582/1000 [06:56<04:54,  1.42it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 583/1000 [06:57<04:54,  1.42it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 584/1000 [06:58<04:54,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  58%|█████▊    | 585/1000 [06:59<04:55,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▊    | 586/1000 [06:59<04:54,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▊    | 587/1000 [07:00<04:53,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▉    | 588/1000 [07:01<04:52,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▉    | 589/1000 [07:01<04:51,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▉    | 590/1000 [07:02<04:51,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▉    | 591/1000 [07:03<04:50,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▉    | 592/1000 [07:04<04:48,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▉    | 593/1000 [07:04<04:49,  1.40it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  59%|█████▉    | 594/1000 [07:05<04:48,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  60%|█████▉    | 595/1000 [07:06<04:47,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  60%|█████▉    | 596/1000 [07:06<04:46,  1.41it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  60%|█████▉    | 597/1000 [07:07<04:46,  1.40it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  60%|█████▉    | 598/1000 [07:08<04:56,  1.35it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  60%|█████▉    | 599/1000 [07:09<04:52,  1.37it/s]\u001b[A\n","Training - loss 0.207 - factual_f1 0.463 - misinfo_f1 0.962 - val_loss 0.171 - val_factual_f1 0.072 - val_misinfo_f1 0.981:  60%|██████    | 600/1000 [07:09<04:48,  1.39it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  60%|██████    | 600/1000 [07:10<04:48,  1.39it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  60%|██████    | 601/1000 [07:10<04:47,  1.39it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  60%|██████    | 602/1000 [07:11<04:45,  1.39it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  60%|██████    | 603/1000 [07:11<04:44,  1.40it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  60%|██████    | 604/1000 [07:12<04:43,  1.40it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  60%|██████    | 605/1000 [07:13<04:41,  1.40it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████    | 606/1000 [07:14<04:40,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████    | 607/1000 [07:14<04:39,  1.40it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████    | 608/1000 [07:15<04:38,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████    | 609/1000 [07:16<04:37,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████    | 610/1000 [07:16<04:36,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████    | 611/1000 [07:17<04:36,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████    | 612/1000 [07:18<04:35,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████▏   | 613/1000 [07:19<04:33,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  61%|██████▏   | 614/1000 [07:19<04:32,  1.42it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 615/1000 [07:20<04:32,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 616/1000 [07:21<04:31,  1.42it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 617/1000 [07:21<04:30,  1.42it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 618/1000 [07:22<04:30,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 619/1000 [07:23<04:29,  1.42it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 620/1000 [07:23<04:28,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 621/1000 [07:24<04:27,  1.42it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 622/1000 [07:25<04:27,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 623/1000 [07:26<04:26,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▏   | 624/1000 [07:26<04:26,  1.41it/s]\u001b[A\n","Training - loss 0.198 - factual_f1 0.487 - misinfo_f1 0.962 - val_loss 0.166 - val_factual_f1 0.032 - val_misinfo_f1 0.983:  62%|██████▎   | 625/1000 [07:27<04:25,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  62%|██████▎   | 625/1000 [07:28<04:25,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 626/1000 [07:28<04:25,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 627/1000 [07:28<04:25,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 628/1000 [07:29<04:23,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 629/1000 [07:30<04:21,  1.42it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 630/1000 [07:31<04:21,  1.42it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 631/1000 [07:31<04:21,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 632/1000 [07:32<04:19,  1.42it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 633/1000 [07:33<04:19,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  63%|██████▎   | 634/1000 [07:33<04:19,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▎   | 635/1000 [07:34<04:19,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▎   | 636/1000 [07:35<04:18,  1.41it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▎   | 637/1000 [07:36<04:20,  1.39it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 638/1000 [07:36<04:20,  1.39it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 639/1000 [07:37<04:19,  1.39it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 640/1000 [07:38<04:17,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 641/1000 [07:38<04:17,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 642/1000 [07:39<04:15,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 643/1000 [07:40<04:14,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 644/1000 [07:41<04:14,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  64%|██████▍   | 645/1000 [07:41<04:13,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  65%|██████▍   | 646/1000 [07:42<04:12,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  65%|██████▍   | 647/1000 [07:43<04:12,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  65%|██████▍   | 648/1000 [07:43<04:11,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  65%|██████▍   | 649/1000 [07:44<04:11,  1.40it/s]\u001b[A\n","Training - loss 0.191 - factual_f1 0.527 - misinfo_f1 0.963 - val_loss 0.190 - val_factual_f1 0.023 - val_misinfo_f1 0.977:  65%|██████▌   | 650/1000 [07:45<04:12,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  65%|██████▌   | 650/1000 [07:46<04:12,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  65%|██████▌   | 651/1000 [07:46<04:12,  1.38it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  65%|██████▌   | 652/1000 [07:46<04:11,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  65%|██████▌   | 653/1000 [07:47<04:08,  1.40it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  65%|██████▌   | 654/1000 [07:48<04:08,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 655/1000 [07:48<04:07,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 656/1000 [07:49<04:06,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 657/1000 [07:50<04:06,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 658/1000 [07:51<04:05,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 659/1000 [07:51<04:04,  1.39it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 660/1000 [07:52<04:03,  1.40it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 661/1000 [07:53<04:02,  1.40it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▌   | 662/1000 [07:53<04:01,  1.40it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▋   | 663/1000 [07:54<03:59,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▋   | 664/1000 [07:55<03:58,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  66%|██████▋   | 665/1000 [07:56<03:57,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 666/1000 [07:56<03:56,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 667/1000 [07:57<03:55,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 668/1000 [07:58<03:54,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 669/1000 [07:58<03:54,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 670/1000 [07:59<03:53,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 671/1000 [08:00<03:52,  1.42it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 672/1000 [08:01<03:51,  1.41it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 673/1000 [08:01<03:50,  1.42it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  67%|██████▋   | 674/1000 [08:02<03:50,  1.42it/s]\u001b[A\n","Training - loss 0.192 - factual_f1 0.516 - misinfo_f1 0.962 - val_loss 0.219 - val_factual_f1 0.021 - val_misinfo_f1 0.975:  68%|██████▊   | 675/1000 [08:03<03:49,  1.42it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 675/1000 [08:03<03:49,  1.42it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 676/1000 [08:03<03:48,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 677/1000 [08:04<03:48,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 678/1000 [08:05<03:48,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 679/1000 [08:05<03:47,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 680/1000 [08:06<03:46,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 681/1000 [08:07<03:46,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 682/1000 [08:08<03:45,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 683/1000 [08:08<03:44,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 684/1000 [08:09<03:43,  1.42it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  68%|██████▊   | 685/1000 [08:10<03:43,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▊   | 686/1000 [08:10<03:42,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▊   | 687/1000 [08:11<03:41,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▉   | 688/1000 [08:12<03:40,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▉   | 689/1000 [08:13<03:40,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▉   | 690/1000 [08:13<03:39,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▉   | 691/1000 [08:14<03:38,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▉   | 692/1000 [08:15<03:38,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▉   | 693/1000 [08:15<03:37,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  69%|██████▉   | 694/1000 [08:16<03:36,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  70%|██████▉   | 695/1000 [08:17<03:35,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  70%|██████▉   | 696/1000 [08:17<03:35,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  70%|██████▉   | 697/1000 [08:18<03:34,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  70%|██████▉   | 698/1000 [08:19<03:34,  1.41it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  70%|██████▉   | 699/1000 [08:20<03:34,  1.40it/s]\u001b[A\n","Training - loss 0.181 - factual_f1 0.564 - misinfo_f1 0.967 - val_loss 0.228 - val_factual_f1 0.000 - val_misinfo_f1 0.970:  70%|███████   | 700/1000 [08:20<03:33,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  70%|███████   | 700/1000 [08:21<03:33,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  70%|███████   | 701/1000 [08:21<03:31,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  70%|███████   | 702/1000 [08:22<03:31,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  70%|███████   | 703/1000 [08:22<03:29,  1.42it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  70%|███████   | 704/1000 [08:23<03:29,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  70%|███████   | 705/1000 [08:24<03:28,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████   | 706/1000 [08:25<03:36,  1.36it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████   | 707/1000 [08:25<03:33,  1.37it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████   | 708/1000 [08:26<03:30,  1.39it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████   | 709/1000 [08:27<03:28,  1.40it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████   | 710/1000 [08:28<03:27,  1.40it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████   | 711/1000 [08:28<03:26,  1.40it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████   | 712/1000 [08:29<03:24,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████▏  | 713/1000 [08:30<03:23,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  71%|███████▏  | 714/1000 [08:30<03:23,  1.40it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 715/1000 [08:31<03:23,  1.40it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 716/1000 [08:32<03:21,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 717/1000 [08:32<03:21,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 718/1000 [08:33<03:21,  1.40it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 719/1000 [08:34<03:19,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 720/1000 [08:35<03:18,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 721/1000 [08:35<03:17,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 722/1000 [08:36<03:17,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 723/1000 [08:37<03:16,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▏  | 724/1000 [08:37<03:16,  1.41it/s]\u001b[A\n","Training - loss 0.177 - factual_f1 0.574 - misinfo_f1 0.966 - val_loss 0.216 - val_factual_f1 0.042 - val_misinfo_f1 0.973:  72%|███████▎  | 725/1000 [08:38<03:16,  1.40it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  72%|███████▎  | 725/1000 [08:39<03:16,  1.40it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 726/1000 [08:39<03:16,  1.39it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 727/1000 [08:40<03:15,  1.40it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 728/1000 [08:40<03:14,  1.40it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 729/1000 [08:41<03:13,  1.40it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 730/1000 [08:42<03:12,  1.40it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 731/1000 [08:42<03:12,  1.40it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 732/1000 [08:43<03:10,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 733/1000 [08:44<03:09,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  73%|███████▎  | 734/1000 [08:45<03:08,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▎  | 735/1000 [08:45<03:07,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▎  | 736/1000 [08:46<03:06,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▎  | 737/1000 [08:47<03:05,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 738/1000 [08:47<03:05,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 739/1000 [08:48<03:04,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 740/1000 [08:49<03:03,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 741/1000 [08:50<03:02,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 742/1000 [08:50<03:01,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 743/1000 [08:51<03:00,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 744/1000 [08:52<03:01,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  74%|███████▍  | 745/1000 [08:52<03:00,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  75%|███████▍  | 746/1000 [08:53<02:59,  1.41it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  75%|███████▍  | 747/1000 [08:54<02:58,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  75%|███████▍  | 748/1000 [08:54<02:57,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  75%|███████▍  | 749/1000 [08:55<02:56,  1.42it/s]\u001b[A\n","Training - loss 0.166 - factual_f1 0.606 - misinfo_f1 0.969 - val_loss 0.231 - val_factual_f1 0.055 - val_misinfo_f1 0.971:  75%|███████▌  | 750/1000 [08:56<02:56,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  75%|███████▌  | 750/1000 [08:57<02:56,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  75%|███████▌  | 751/1000 [08:57<02:56,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  75%|███████▌  | 752/1000 [08:57<02:55,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  75%|███████▌  | 753/1000 [08:58<02:54,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  75%|███████▌  | 754/1000 [08:59<02:54,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 755/1000 [08:59<02:53,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 756/1000 [09:00<02:53,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 757/1000 [09:01<02:52,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 758/1000 [09:02<02:52,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 759/1000 [09:02<02:51,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 760/1000 [09:03<02:49,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 761/1000 [09:04<02:49,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▌  | 762/1000 [09:04<02:49,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▋  | 763/1000 [09:05<02:48,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▋  | 764/1000 [09:06<02:48,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  76%|███████▋  | 765/1000 [09:07<02:47,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 766/1000 [09:07<02:47,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 767/1000 [09:08<02:46,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 768/1000 [09:09<02:45,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 769/1000 [09:09<02:45,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 770/1000 [09:10<02:43,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 771/1000 [09:11<02:43,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 772/1000 [09:12<02:42,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 773/1000 [09:12<02:41,  1.40it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  77%|███████▋  | 774/1000 [09:13<02:40,  1.41it/s]\u001b[A\n","Training - loss 0.173 - factual_f1 0.570 - misinfo_f1 0.967 - val_loss 0.244 - val_factual_f1 0.023 - val_misinfo_f1 0.968:  78%|███████▊  | 775/1000 [09:14<02:40,  1.40it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 775/1000 [09:14<02:40,  1.40it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 776/1000 [09:14<02:40,  1.40it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 777/1000 [09:15<02:39,  1.40it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 778/1000 [09:16<02:38,  1.40it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 779/1000 [09:17<02:36,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 780/1000 [09:17<02:35,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 781/1000 [09:18<02:34,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 782/1000 [09:19<02:34,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 783/1000 [09:19<02:33,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 784/1000 [09:20<02:33,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  78%|███████▊  | 785/1000 [09:21<02:32,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▊  | 786/1000 [09:21<02:32,  1.40it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▊  | 787/1000 [09:22<02:31,  1.40it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▉  | 788/1000 [09:23<02:30,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▉  | 789/1000 [09:24<02:29,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▉  | 790/1000 [09:24<02:28,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▉  | 791/1000 [09:25<02:27,  1.41it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▉  | 792/1000 [09:26<02:26,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▉  | 793/1000 [09:26<02:25,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  79%|███████▉  | 794/1000 [09:27<02:25,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  80%|███████▉  | 795/1000 [09:28<02:24,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  80%|███████▉  | 796/1000 [09:29<02:23,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  80%|███████▉  | 797/1000 [09:29<02:22,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  80%|███████▉  | 798/1000 [09:30<02:22,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  80%|███████▉  | 799/1000 [09:31<02:21,  1.42it/s]\u001b[A\n","Training - loss 0.167 - factual_f1 0.613 - misinfo_f1 0.969 - val_loss 0.243 - val_factual_f1 0.006 - val_misinfo_f1 0.966:  80%|████████  | 800/1000 [09:31<02:20,  1.42it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  80%|████████  | 800/1000 [09:32<02:20,  1.42it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  80%|████████  | 801/1000 [09:32<02:20,  1.42it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  80%|████████  | 802/1000 [09:33<02:20,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  80%|████████  | 803/1000 [09:33<02:20,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  80%|████████  | 804/1000 [09:34<02:20,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  80%|████████  | 805/1000 [09:35<02:20,  1.39it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████  | 806/1000 [09:36<02:18,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████  | 807/1000 [09:36<02:17,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████  | 808/1000 [09:37<02:16,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████  | 809/1000 [09:38<02:15,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████  | 810/1000 [09:38<02:14,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████  | 811/1000 [09:39<02:13,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████  | 812/1000 [09:40<02:12,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████▏ | 813/1000 [09:41<02:17,  1.36it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  81%|████████▏ | 814/1000 [09:41<02:14,  1.38it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 815/1000 [09:42<02:13,  1.38it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 816/1000 [09:43<02:12,  1.38it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 817/1000 [09:44<02:11,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 818/1000 [09:44<02:09,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 819/1000 [09:45<02:08,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 820/1000 [09:46<02:08,  1.40it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 821/1000 [09:46<02:07,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 822/1000 [09:47<02:06,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 823/1000 [09:48<02:05,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▏ | 824/1000 [09:48<02:04,  1.41it/s]\u001b[A\n","Training - loss 0.158 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.256 - val_factual_f1 0.048 - val_misinfo_f1 0.968:  82%|████████▎ | 825/1000 [09:49<02:04,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  82%|████████▎ | 825/1000 [09:50<02:04,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 826/1000 [09:50<02:03,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 827/1000 [09:51<02:03,  1.40it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 828/1000 [09:51<02:02,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 829/1000 [09:52<02:01,  1.40it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 830/1000 [09:53<02:00,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 831/1000 [09:53<01:59,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 832/1000 [09:54<01:59,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 833/1000 [09:55<01:58,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  83%|████████▎ | 834/1000 [09:56<01:57,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▎ | 835/1000 [09:56<01:57,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▎ | 836/1000 [09:57<01:56,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▎ | 837/1000 [09:58<01:55,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 838/1000 [09:58<01:54,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 839/1000 [09:59<01:53,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 840/1000 [10:00<01:52,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 841/1000 [10:01<01:52,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 842/1000 [10:01<01:51,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 843/1000 [10:02<01:50,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 844/1000 [10:03<01:50,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  84%|████████▍ | 845/1000 [10:03<01:49,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  85%|████████▍ | 846/1000 [10:04<01:49,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  85%|████████▍ | 847/1000 [10:05<01:48,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  85%|████████▍ | 848/1000 [10:06<01:47,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  85%|████████▍ | 849/1000 [10:06<01:47,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.606 - misinfo_f1 0.967 - val_loss 0.261 - val_factual_f1 0.078 - val_misinfo_f1 0.969:  85%|████████▌ | 850/1000 [10:07<01:46,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  85%|████████▌ | 850/1000 [10:08<01:46,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  85%|████████▌ | 851/1000 [10:08<01:45,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  85%|████████▌ | 852/1000 [10:08<01:45,  1.40it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  85%|████████▌ | 853/1000 [10:09<01:44,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  85%|████████▌ | 854/1000 [10:10<01:43,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 855/1000 [10:10<01:42,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 856/1000 [10:11<01:41,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 857/1000 [10:12<01:41,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 858/1000 [10:13<01:40,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 859/1000 [10:13<01:39,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 860/1000 [10:14<01:39,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 861/1000 [10:15<01:38,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▌ | 862/1000 [10:15<01:38,  1.40it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▋ | 863/1000 [10:16<01:37,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▋ | 864/1000 [10:17<01:36,  1.40it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  86%|████████▋ | 865/1000 [10:18<01:35,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 866/1000 [10:18<01:35,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 867/1000 [10:19<01:34,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 868/1000 [10:20<01:33,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 869/1000 [10:20<01:32,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 870/1000 [10:21<01:31,  1.42it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 871/1000 [10:22<01:31,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 872/1000 [10:23<01:30,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 873/1000 [10:23<01:29,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  87%|████████▋ | 874/1000 [10:24<01:29,  1.41it/s]\u001b[A\n","Training - loss 0.169 - factual_f1 0.593 - misinfo_f1 0.968 - val_loss 0.255 - val_factual_f1 0.066 - val_misinfo_f1 0.970:  88%|████████▊ | 875/1000 [10:25<01:28,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 875/1000 [10:25<01:28,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 876/1000 [10:25<01:28,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 877/1000 [10:26<01:27,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 878/1000 [10:27<01:26,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 879/1000 [10:28<01:26,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 880/1000 [10:28<01:25,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 881/1000 [10:29<01:24,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 882/1000 [10:30<01:23,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 883/1000 [10:30<01:23,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 884/1000 [10:31<01:22,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  88%|████████▊ | 885/1000 [10:32<01:22,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▊ | 886/1000 [10:33<01:21,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▊ | 887/1000 [10:33<01:20,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▉ | 888/1000 [10:34<01:20,  1.39it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▉ | 889/1000 [10:35<01:19,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▉ | 890/1000 [10:35<01:18,  1.40it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▉ | 891/1000 [10:36<01:17,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▉ | 892/1000 [10:37<01:16,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▉ | 893/1000 [10:37<01:15,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  89%|████████▉ | 894/1000 [10:38<01:15,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  90%|████████▉ | 895/1000 [10:39<01:14,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  90%|████████▉ | 896/1000 [10:40<01:13,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  90%|████████▉ | 897/1000 [10:40<01:13,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  90%|████████▉ | 898/1000 [10:41<01:12,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  90%|████████▉ | 899/1000 [10:42<01:11,  1.41it/s]\u001b[A\n","Training - loss 0.160 - factual_f1 0.637 - misinfo_f1 0.969 - val_loss 0.258 - val_factual_f1 0.050 - val_misinfo_f1 0.970:  90%|█████████ | 900/1000 [10:42<01:11,  1.40it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  90%|█████████ | 900/1000 [10:43<01:11,  1.40it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  90%|█████████ | 901/1000 [10:43<01:10,  1.40it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  90%|█████████ | 902/1000 [10:44<01:10,  1.40it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  90%|█████████ | 903/1000 [10:45<01:09,  1.40it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  90%|█████████ | 904/1000 [10:45<01:08,  1.39it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  90%|█████████ | 905/1000 [10:46<01:07,  1.40it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████ | 906/1000 [10:47<01:06,  1.40it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████ | 907/1000 [10:47<01:05,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████ | 908/1000 [10:48<01:04,  1.42it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████ | 909/1000 [10:49<01:04,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████ | 910/1000 [10:50<01:03,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████ | 911/1000 [10:50<01:02,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████ | 912/1000 [10:51<01:02,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████▏| 913/1000 [10:52<01:01,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  91%|█████████▏| 914/1000 [10:52<01:00,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 915/1000 [10:53<00:59,  1.42it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 916/1000 [10:54<00:59,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 917/1000 [10:55<00:58,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 918/1000 [10:55<00:58,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 919/1000 [10:56<00:57,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 920/1000 [10:57<00:56,  1.41it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 921/1000 [10:57<00:58,  1.35it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 922/1000 [10:58<00:56,  1.37it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 923/1000 [10:59<00:55,  1.38it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▏| 924/1000 [11:00<00:54,  1.39it/s]\u001b[A\n","Training - loss 0.157 - factual_f1 0.631 - misinfo_f1 0.969 - val_loss 0.271 - val_factual_f1 0.085 - val_misinfo_f1 0.967:  92%|█████████▎| 925/1000 [11:00<00:53,  1.40it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  92%|█████████▎| 925/1000 [11:01<00:53,  1.40it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 926/1000 [11:01<00:52,  1.40it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 927/1000 [11:02<00:52,  1.40it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 928/1000 [11:02<00:51,  1.40it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 929/1000 [11:03<00:50,  1.40it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 930/1000 [11:04<00:49,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 931/1000 [11:05<00:48,  1.42it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 932/1000 [11:05<00:48,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 933/1000 [11:06<00:47,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  93%|█████████▎| 934/1000 [11:07<00:46,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▎| 935/1000 [11:07<00:46,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▎| 936/1000 [11:08<00:45,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▎| 937/1000 [11:09<00:44,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 938/1000 [11:10<00:43,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 939/1000 [11:10<00:43,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 940/1000 [11:11<00:42,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 941/1000 [11:12<00:41,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 942/1000 [11:12<00:41,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 943/1000 [11:13<00:40,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 944/1000 [11:14<00:39,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  94%|█████████▍| 945/1000 [11:14<00:38,  1.42it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  95%|█████████▍| 946/1000 [11:15<00:38,  1.42it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  95%|█████████▍| 947/1000 [11:16<00:37,  1.42it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  95%|█████████▍| 948/1000 [11:17<00:36,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  95%|█████████▍| 949/1000 [11:17<00:36,  1.41it/s]\u001b[A\n","Training - loss 0.176 - factual_f1 0.555 - misinfo_f1 0.966 - val_loss 0.261 - val_factual_f1 0.093 - val_misinfo_f1 0.968:  95%|█████████▌| 950/1000 [11:18<00:35,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  95%|█████████▌| 950/1000 [11:19<00:35,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  95%|█████████▌| 951/1000 [11:19<00:34,  1.40it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  95%|█████████▌| 952/1000 [11:19<00:34,  1.40it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  95%|█████████▌| 953/1000 [11:20<00:33,  1.40it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  95%|█████████▌| 954/1000 [11:21<00:32,  1.40it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 955/1000 [11:22<00:31,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 956/1000 [11:22<00:31,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 957/1000 [11:23<00:30,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 958/1000 [11:24<00:29,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 959/1000 [11:24<00:28,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 960/1000 [11:25<00:28,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 961/1000 [11:26<00:27,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▌| 962/1000 [11:27<00:26,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▋| 963/1000 [11:27<00:26,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▋| 964/1000 [11:28<00:25,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  96%|█████████▋| 965/1000 [11:29<00:24,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 966/1000 [11:29<00:24,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 967/1000 [11:30<00:23,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 968/1000 [11:31<00:22,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 969/1000 [11:31<00:21,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 970/1000 [11:32<00:21,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 971/1000 [11:33<00:20,  1.42it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 972/1000 [11:34<00:19,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 973/1000 [11:34<00:19,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  97%|█████████▋| 974/1000 [11:35<00:18,  1.41it/s]\u001b[A\n","Training - loss 0.161 - factual_f1 0.616 - misinfo_f1 0.969 - val_loss 0.226 - val_factual_f1 0.082 - val_misinfo_f1 0.969:  98%|█████████▊| 975/1000 [11:36<00:17,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 975/1000 [11:36<00:17,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 976/1000 [11:36<00:17,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 977/1000 [11:37<00:16,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 978/1000 [11:38<00:15,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 979/1000 [11:39<00:14,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 980/1000 [11:39<00:14,  1.42it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 981/1000 [11:40<00:13,  1.42it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 982/1000 [11:41<00:12,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 983/1000 [11:41<00:12,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 984/1000 [11:42<00:11,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  98%|█████████▊| 985/1000 [11:43<00:10,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▊| 986/1000 [11:44<00:09,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▊| 987/1000 [11:44<00:09,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▉| 988/1000 [11:45<00:08,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▉| 989/1000 [11:46<00:07,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▉| 990/1000 [11:46<00:07,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▉| 991/1000 [11:47<00:06,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▉| 992/1000 [11:48<00:05,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▉| 993/1000 [11:49<00:04,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974:  99%|█████████▉| 994/1000 [11:49<00:04,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974: 100%|█████████▉| 995/1000 [11:50<00:03,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974: 100%|█████████▉| 996/1000 [11:51<00:02,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974: 100%|█████████▉| 997/1000 [11:51<00:02,  1.41it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974: 100%|█████████▉| 998/1000 [11:52<00:01,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974: 100%|█████████▉| 999/1000 [11:53<00:00,  1.40it/s]\u001b[A\n","Training - loss 0.187 - factual_f1 0.543 - misinfo_f1 0.962 - val_loss 0.210 - val_factual_f1 0.120 - val_misinfo_f1 0.974: 100%|██████████| 1000/1000 [11:54<00:00,  1.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["*** Test results ***\n","Factual F1: 0.0476\n","Misinformation F1: 0.9544\n","Macro-average F1: 0.5010\n"]}],"source":["rel = ('reply', 'reply_to', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"s4t9SYsuew-1"},"source":["## 'claim', 'discusses_inv', 'tweet'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82275,"status":"ok","timestamp":1661170138496,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"dQYv8DBYB7h3","outputId":"0d43b707-5012-4e52-8ac2-938609604f69"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training - loss 0.000 - factual_f1 1.000 - misinfo_f1 1.000 - val_loss 22.023 - val_factual_f1 0.022 - val_misinfo_f1 0.332: 100%|██████████| 1000/1000 [01:22<00:00, 12.17it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.1097\n","Misinformation F1: 0.5475\n","Macro-average F1: 0.3286\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rel = ('claim', 'discusses_inv', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"z2UQzgntfZqQ"},"source":["## 'reply', 'quote_of', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":741027,"status":"ok","timestamp":1661170879515,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"AyCb2KiAB7a5","outputId":"d42205fa-64c2-4a0c-f38d-c274161d562b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training - loss 0.133 - factual_f1 0.712 - misinfo_f1 0.976 - val_loss 0.522 - val_factual_f1 0.165 - val_misinfo_f1 0.971: 100%|██████████| 1000/1000 [12:20<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.1967\n","Misinformation F1: 0.9430\n","Macro-average F1: 0.5698\n"]}],"source":["rel = ('reply', 'quote_of', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"76tuRi5HfYdz"},"source":["## 'article', 'has_article_inv', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78594,"status":"ok","timestamp":1661170958106,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"wLwkjCm-B7PO","outputId":"9dd9e61a-128e-4b8f-a2f5-dbe7a740c567"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training - loss 0.168 - factual_f1 0.647 - misinfo_f1 0.971 - val_loss 0.205 - val_factual_f1 0.053 - val_misinfo_f1 0.976: 100%|██████████| 1000/1000 [01:18<00:00, 12.81it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.1875\n","Misinformation F1: 0.9707\n","Macro-average F1: 0.5791\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rel = ('article', 'has_article_inv', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"FANaW6fX9co6"},"source":["## 'hashtag', 'has_hashtag_inv', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39214,"status":"ok","timestamp":1661170997311,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"MMjooRn3B63n","outputId":"4363a61f-689a-4b8e-9d83-89355dccdf80"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training - loss 0.254 - factual_f1 0.192 - misinfo_f1 0.953 - val_loss 0.121 - val_factual_f1 0.015 - val_misinfo_f1 0.991: 100%|██████████| 1000/1000 [00:39<00:00, 25.61it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.0833\n","Misinformation F1: 0.9754\n","Macro-average F1: 0.5294\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rel = ('hashtag', 'has_hashtag_inv', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"ftRPN1zQ9mbt"},"source":["## 'image', 'has_image_inv', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30347,"status":"ok","timestamp":1661171027652,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"b5xvAunL9lai","outputId":"509c82d0-a930-481a-e19f-a0f742f08246"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training - loss 0.193 - factual_f1 0.507 - misinfo_f1 0.965 - val_loss 9.734 - val_factual_f1 0.035 - val_misinfo_f1 0.887: 100%|██████████| 1000/1000 [00:30<00:00, 33.18it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.1538\n","Misinformation F1: 0.8922\n","Macro-average F1: 0.5230\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rel = ('image', 'has_image_inv', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"zAs3Lbih-vWH"},"source":["## 'user', 'mentions_inv', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63472,"status":"ok","timestamp":1661171091114,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"itTh_W40-weE","outputId":"22a6eaa4-dc58-437a-92e2-55dd24e0e621"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training - loss 0.224 - factual_f1 0.356 - misinfo_f1 0.958 - val_loss 0.897 - val_factual_f1 0.075 - val_misinfo_f1 0.977: 100%|██████████| 1000/1000 [01:03<00:00, 15.82it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.0000\n","Misinformation F1: 0.9474\n","Macro-average F1: 0.4737\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rel = ('user', 'mentions_inv', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"T017EmSv-2Rh"},"source":["## 'user', 'retweeted', 'tweet'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213527,"status":"ok","timestamp":1661171323202,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"zKC3mUAs-6lA","outputId":"1e6e215f-6f5a-40a3-c341-492c9a269cee"},"outputs":[{"output_type":"stream","name":"stderr","text":["Training - loss 0.172 - factual_f1 0.567 - misinfo_f1 0.965 - val_loss 2.828 - val_factual_f1 0.074 - val_misinfo_f1 0.958: 100%|██████████| 1000/1000 [03:32<00:00,  4.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","*** Test results ***\n","Factual F1: 0.1481\n","Misinformation F1: 0.9469\n","Macro-average F1: 0.5475\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rel = ('user', 'retweeted', 'tweet')\n","subgraph = dgl.edge_type_subgraph(dgl_graph, etypes=[rel]).to('cuda')\n","subgraph\n","\n","train_mask = subgraph.nodes['tweet'].data['train_mask']\n","val_mask = subgraph.nodes['tweet'].data['val_mask']\n","test_mask = subgraph.nodes['tweet'].data['test_mask']\n","\n","class SAGEClassifier(nn.Module):\n","    def __init__(self, hidden_dim: int = 500):\n","        super().__init__()\n","        feats1 = subgraph.nodes[rel[0]].data['feat'].shape[-1]\n","        feats2 = subgraph.nodes[rel[2]].data['feat'].shape[-1]\n","        self.conv = dglnn.SAGEConv(in_feats=(feats1, feats2), \n","                                   out_feats=hidden_dim, \n","                                   aggregator_type='lstm',\n","                                   activation=nn.GELU())\n","        self.clf = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.2),\n","            nn.BatchNorm1d(hidden_dim),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","\n","    def forward(self, graph, x):\n","        x = self.conv(graph, (x['p1'], x['p2']))\n","        x = self.clf(x)\n","        return x\n","\n","gnn = SAGEClassifier().cuda()\n","gnn\n","\n","def forward_pass() -> dict:\n","    '''A forward pass of the graph neural network.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Set the GNN to training mode\n","    gnn.train()\n","\n","    # Get the input features and the output labels\n","    input_feats = dict(\n","        p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","        p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","    )\n","    output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","    # Forward propagation\n","    logits = gnn(subgraph, input_feats).squeeze()\n","\n","    # Compute loss\n","    loss = F.binary_cross_entropy_with_logits(\n","        input=logits[train_mask],\n","        target=output_labels.float()[train_mask]\n","    )\n","\n","    # Compute training metrics\n","    scores = scorer(logits[train_mask].ge(0), output_labels[train_mask])\n","    misinformation_f1 = scores[0]\n","    factual_f1 = scores[1]\n","\n","    return dict(loss=loss, \n","                misinformation_f1=misinformation_f1, \n","                factual_f1=factual_f1)\n","\n","def evaluate(split: str) -> dict:\n","    '''Evaluate the graph neural network.\n","\n","    Args:\n","        split (str):\n","            The split to evaluate the GNN on. Can be 'val' or 'test'.\n","\n","    Returns:\n","        dict:\n","            A dict with keys 'loss', 'misinformation_f1' and 'factual_f1', \n","            with values as their corresponding values.\n","    '''\n","    # Get the correct mask, depending on the value of `split`\n","    mask = val_mask if split == 'val' else test_mask\n","\n","    gnn.eval()\n","    with torch.no_grad():\n","\n","        # Get the input features and the output labels\n","        input_feats = dict(\n","            p1=subgraph.nodes[rel[0]].data['feat'].float().cuda(),\n","            p2=subgraph.nodes[rel[2]].data['feat'].float().cuda()\n","        )\n","        output_labels = subgraph.nodes['tweet'].data['label'].cuda()\n","\n","        # Forward propagation\n","        logits = gnn(subgraph, input_feats).squeeze()\n","\n","        # Compute validation loss\n","        val_loss = F.binary_cross_entropy_with_logits(\n","            input=logits[mask],\n","            target=output_labels.float()[mask]\n","        ).cpu().item()\n","\n","        # Compute validation metrics\n","        scores = scorer(logits[mask].ge(0), output_labels[mask])\n","        val_misinformation_f1 = scores[0].cpu().item()\n","        val_factual_f1 = scores[1].cpu().item()\n","\n","    return dict(loss=val_loss, \n","                misinformation_f1=val_misinformation_f1, \n","                factual_f1=val_factual_f1)\n","\n","# Initialise optimiser\n","opt = optim.AdamW(gnn.parameters(), lr=3e-4)\n","\n","# Initialise scorer\n","scorer = tm.classification.f_beta.F1Score(num_classes=2, average='none').cuda()\n","\n","# Initialise dictionary containing validation scores\n","val_scores = defaultdict(list)\n","\n","# Initialise progress bar\n","epoch_pbar = tqdm(range(1000), desc='Training')\n","\n","for epoch in epoch_pbar:\n","\n","    # Reset the gradients\n","    opt.zero_grad()\n","\n","    # Forward propagation\n","    train_results = forward_pass()\n","\n","    # Backward propagation\n","    train_results['loss'].backward()\n","\n","    # Update gradients\n","    opt.step()\n","\n","    # Evaluate the model\n","    val_results = evaluate('val')\n","\n","    # Store the validation scores\n","    for metric in ['loss', 'misinformation_f1', 'factual_f1']:\n","        val_scores[metric].append(val_results[metric])\n","\n","    # Update progress bar description\n","    if epoch % 25 == 0 and epoch > 0:\n","        val_loss = np.mean(val_scores['loss'])\n","        val_misinformation_f1 = np.mean(val_scores['misinformation_f1'])\n","        val_factual_f1 = np.mean(val_scores['factual_f1'])\n","        desc = (f'Training - '\n","                f'loss {train_results[\"loss\"]:.3f} - '\n","                f'factual_f1 {train_results[\"factual_f1\"]:.3f} - '\n","                f'misinfo_f1 {train_results[\"misinformation_f1\"]:.3f} - '\n","                f'val_loss {val_loss:.3f} - '\n","                f'val_factual_f1 {val_factual_f1:.3f} - '\n","                f'val_misinfo_f1 {val_misinformation_f1:.3f}')\n","        epoch_pbar.set_description(desc)\n","        val_scores = defaultdict(list)\n","\n","test_results = evaluate('test')\n","macro_f1 = np.mean([test_results['factual_f1'],\n","                    test_results['misinformation_f1']])\n","print()\n","print('*** Test results ***')\n","print(f'Factual F1: {test_results[\"factual_f1\"]:.4f}')\n","print(f'Misinformation F1: {test_results[\"misinformation_f1\"]:.4f}')\n","print(f'Macro-average F1: {macro_f1:.4f}')"]},{"cell_type":"markdown","metadata":{"id":"AEaVtbRy_eLD"},"source":["## performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JgY6Nb_I_E2h"},"outputs":[],"source":["model_performance = dict()\n","model_performance['user_posted_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.1633, 0.9529, 0.5581, 53)))\n","model_performance['reply_reply_to_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.1644, 0.9280, 0.5462, 6923)))\n","model_performance['claim_discusses_inv_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.1044, 0.4137, 0.2590, 92)))\n","model_performance['reply_quote_of_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.1791, 0.9355, 0.5573, 7804)))\n","model_performance['article_has_article_inv_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.1795, 0.9240, 0.5517, 86)))\n","model_performance['hashtag_has_hashtag_inv_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.0800, 0.9743, 0.5272, 60)))\n","model_performance['image_has_image_inv_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.1653, 0.8736, 0.5194, 37)))\n","model_performance['user_mentions_inv_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.0000, 0.9486, 0.4743, 75)))\n","model_performance['user_retweeted_tweet'] = dict(zip(('Factual F1', 'Misinformation F1', 'Macro-average F1', 'Training Time'), (0.1455, 0.9457, 0.5456, 233)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1660123629334,"user":{"displayName":"胡皓量","userId":"01966224964779321794"},"user_tz":-480},"id":"l6_oUO83Ap7A","outputId":"064575bd-111b-445a-9ff1-454e0ccbe383"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-c8d52e4f-341c-4e49-b51e-a0826d14aed8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Factual F1</th>\n","      <th>Misinformation F1</th>\n","      <th>Macro-average F1</th>\n","      <th>Training Time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>user_posted_tweet</th>\n","      <td>0.1633</td>\n","      <td>0.9529</td>\n","      <td>0.5581</td>\n","      <td>53.0</td>\n","    </tr>\n","    <tr>\n","      <th>reply_quote_of_tweet</th>\n","      <td>0.1791</td>\n","      <td>0.9355</td>\n","      <td>0.5573</td>\n","      <td>7804.0</td>\n","    </tr>\n","    <tr>\n","      <th>article_has_article_inv_tweet</th>\n","      <td>0.1795</td>\n","      <td>0.9240</td>\n","      <td>0.5517</td>\n","      <td>86.0</td>\n","    </tr>\n","    <tr>\n","      <th>reply_reply_to_tweet</th>\n","      <td>0.1644</td>\n","      <td>0.9280</td>\n","      <td>0.5462</td>\n","      <td>6923.0</td>\n","    </tr>\n","    <tr>\n","      <th>user_retweeted_tweet</th>\n","      <td>0.1455</td>\n","      <td>0.9457</td>\n","      <td>0.5456</td>\n","      <td>233.0</td>\n","    </tr>\n","    <tr>\n","      <th>hashtag_has_hashtag_inv_tweet</th>\n","      <td>0.0800</td>\n","      <td>0.9743</td>\n","      <td>0.5272</td>\n","      <td>60.0</td>\n","    </tr>\n","    <tr>\n","      <th>image_has_image_inv_tweet</th>\n","      <td>0.1653</td>\n","      <td>0.8736</td>\n","      <td>0.5194</td>\n","      <td>37.0</td>\n","    </tr>\n","    <tr>\n","      <th>user_mentions_inv_tweet</th>\n","      <td>0.0000</td>\n","      <td>0.9486</td>\n","      <td>0.4743</td>\n","      <td>75.0</td>\n","    </tr>\n","    <tr>\n","      <th>claim_discusses_inv_tweet</th>\n","      <td>0.1044</td>\n","      <td>0.4137</td>\n","      <td>0.2590</td>\n","      <td>92.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8d52e4f-341c-4e49-b51e-a0826d14aed8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c8d52e4f-341c-4e49-b51e-a0826d14aed8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c8d52e4f-341c-4e49-b51e-a0826d14aed8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                               Factual F1  Misinformation F1  \\\n","user_posted_tweet                  0.1633             0.9529   \n","reply_quote_of_tweet               0.1791             0.9355   \n","article_has_article_inv_tweet      0.1795             0.9240   \n","reply_reply_to_tweet               0.1644             0.9280   \n","user_retweeted_tweet               0.1455             0.9457   \n","hashtag_has_hashtag_inv_tweet      0.0800             0.9743   \n","image_has_image_inv_tweet          0.1653             0.8736   \n","user_mentions_inv_tweet            0.0000             0.9486   \n","claim_discusses_inv_tweet          0.1044             0.4137   \n","\n","                               Macro-average F1  Training Time  \n","user_posted_tweet                        0.5581           53.0  \n","reply_quote_of_tweet                     0.5573         7804.0  \n","article_has_article_inv_tweet            0.5517           86.0  \n","reply_reply_to_tweet                     0.5462         6923.0  \n","user_retweeted_tweet                     0.5456          233.0  \n","hashtag_has_hashtag_inv_tweet            0.5272           60.0  \n","image_has_image_inv_tweet                0.5194           37.0  \n","user_mentions_inv_tweet                  0.4743           75.0  \n","claim_discusses_inv_tweet                0.2590           92.0  "]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","performance = pd.DataFrame(model_performance).T\n","performance.sort_values(by=['Macro-average F1'], ascending=False)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}